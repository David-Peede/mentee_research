{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "500b0181-0648-40fd-9f0a-e2f8ae1b0cc9",
   "metadata": {},
   "source": [
    "# Running a Hidden Markov Model with the Baum-Welch Algorithm on Simulated Ancestral Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b85fb-9cca-45c4-a801-2b4e4e504cab",
   "metadata": {},
   "source": [
    "---\n",
    "## Purpose of Guide\n",
    "Using simulated genomic data of human populations, this Hidden Markov Model infers the likelihood of introgression from an archaic population at each locus on a simulated genome.\n",
    "\n",
    "It further uses the Baum-Welch Algorithm to optimize this detection.\n",
    "In this guide, I'll walk through how to run my HMM from start to finish on a single pre-generated rep id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca41abf7-f7c1-4119-b4ec-1b73bb91f0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.22.3\n",
      "gzip 1.22.3\n",
      "shutil 1.22.3\n",
      "re 1.22.3\n"
     ]
    }
   ],
   "source": [
    "# Import packages.\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import gzip\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "try:\n",
    "    logaddexp = np.logaddexp\n",
    "except AttributeError:\n",
    "    def logaddexp(logx, logy):\n",
    "        if logy - logx > 100:\n",
    "            return logy\n",
    "        elif logx - logy > 100:\n",
    "            return logx\n",
    "        minxy = min(logx, logy)\n",
    "        return minxy + np.log(np.exp(logx - minxy) + np.exp(logy - minxy))\n",
    "\n",
    "# Print versions of our libraries.\n",
    "print('numpy', np.__version__)\n",
    "print('gzip', np.__version__)\n",
    "print('shutil', np.__version__)\n",
    "print('re', np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e41d884-0ec3-4a89-b8a7-357dc3a438b3",
   "metadata": {},
   "source": [
    "---\n",
    "# Function Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ffa8b-63e8-49b6-b7a5-380a0db27b66",
   "metadata": {},
   "source": [
    "---\n",
    "### `genotype_matrix_windows()`\n",
    "#### Purpose:\n",
    "`genotype_matrix_windows()` is a helper function that splits a genotype matrix into non-overlapping windows and assigns positions that are variable across populations to a window according to their position. By default, the length of the simulated genome is 20 million base pairs. Each window is 500 base pairs long, with inclusive/exclusive bounds (ex. [0,500]). This results in 40,000 windows ranging from [0, 20,000,000].\n",
    "#### Input:\n",
    "- `variant_positions`: an array of the positions of variant sites across populations. Each index represents a separate variant (ordered by relative position but not evenly spaced), and its corresponding cell value represents the location of that variant position on the genome.\n",
    "- `polarized_genotype_matrix`: an array of multiple populations. It includes the ancestral population whose introgression is being inferred (Neanderthals), the population in whom introgression is being tested (Europeans), one or more sister populations to the one being tested, as a control (Africans), and an \"ancestral state\" reference population against which the rest can be polarized (Chimpanzee). Only biallelic sites are included. The ancestral allele and all identical populations are represented by '0' while the derived mutated allele is represented by '1'.\n",
    "- `window_size` The size of each window here is set to 500 by default. In Prufer's 2014 paper, the team used a genetic map, with crossover positions. We will map the genetic position by relative physical location on the chromosome \\[0 to 20,000,000).\n",
    "- `sequence_length`: the length of the simulated genome being tested. Set to 20,000,000 by default.\n",
    "\n",
    "#### Output:\n",
    "`windows` (dictionary). It has the following key ==> value relationship:\n",
    "\n",
    "*Window number (from 1 to 40,000) => [window start position, window end position, index of variant position in the input array].*\n",
    "\n",
    "Types are:\n",
    "`int => array[int, int, int...]`\n",
    "\n",
    "If there are multiple variant positions within a window, their indices in the input array of variant positions are appended to the value array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0765f206-5ce0-4fc1-a2e9-795919e0400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genotype_matrix_windows(\n",
    "        variant_positions,\n",
    "        polarized_genotype_matrix,\n",
    "        window_size=500,\n",
    "        sequence_length=20_000_000,\n",
    "):\n",
    "    # Intialize a dictionary with the start and stop position for each window.\n",
    "    windows = {}\n",
    "    index = 1\n",
    "    # Create consistent-length windows spanning the length of the sequence\n",
    "    for window_start in range(0, int(sequence_length), int(window_size)):\n",
    "        # The index (window number) is set as the key to a value of an array which contains its start and stop position\n",
    "        windows[index] = [window_start, (window_start + window_size)]\n",
    "        index += 1\n",
    "    # Locate and assign each variant position to its respective window\n",
    "    # keeps track of index number in the variant_position array\n",
    "    index = 0\n",
    "    pos = variant_positions[index]\n",
    "    for key in windows:\n",
    "        # extract the window bounds\n",
    "        start, stop = windows[key]\n",
    "        # \"bin\" the variant a the window if it is within bounds\n",
    "        while start <= pos < stop:\n",
    "            # append the index of the variant position to the corresponding value array in windows\n",
    "            windows[key].append(index)\n",
    "            index += 1\n",
    "            if index < len(variant_positions):\n",
    "                pos = variant_positions[index]\n",
    "            else: # (all variant positions have been binned)\n",
    "                break\n",
    "    # window # (1-40,000) -> [0 (start), 500 (stop), index of local variable positions (if any)]\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bd99a3-4703-4391-87bc-acd3079f7330",
   "metadata": {},
   "source": [
    "---\n",
    "### `calc_window_intro_percent()`\n",
    "#### Purpose:\n",
    "`calc_window_intro_percent()` stores the locations of genomic regions that are a result of the archaic population introgression that the HMM will infer. Known as \"true introgression positions,\" these segments represent the hidden states of the HMM. In practice, the exact loci in modern human DNA that are a result of Neanderthal introgression cannot be known, so in order to evaluate the model's efficacy and compare its performance, we record the true introgression positions during data simulation to create an \"answer key\".\n",
    "\n",
    "To this end, this function creates a dictionary of windows similar to the one created by `genotype_matrix_windows()`, but instead of recording the bounds and variant positions of each window, it represents how much each window is covered by a segment of \"true introgression\" as a percentage value. The data structure allows the quick identification of areas of true introgression in the genome, which allows the HMM's accuracy to be evaluated.\n",
    "\n",
    "#### Input:\n",
    "- `Binned_windows`: a dictionary where the keys represent the iwndow number from 1 to 40,000 and the values are arrays where the first two elements represent positional boundaries, and any following elements represent the index of variant positions that lie within that window in the `variant_positions` array. Binned_windows is the direct output of `genotype_matrix_windows`.\n",
    "- `true_introgression_positions`: nparray representing the locations of introgressed loci on the genome. Each row represents a different introgressed segment. The first column represents its starting location, and the second column represents its stopping location.\n",
    "\n",
    "#### Output:\n",
    "- `Win_intro_percent`: a dictionary of 500 base pair bins and their contents included to keep track of the true introgression state windows. The key is the window number and the value is a float percentage between 0 and 1 of how much of the window is covered by the true introgression segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52b99e7a-81c0-49ca-b97a-5d525953ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_window_intro_percent(Binned_windows, true_introgression_positions):\n",
    "\n",
    "    Windows = Binned_windows\n",
    "    true_intro_pos = true_introgression_positions\n",
    "    \n",
    "    # Initializing dictionary of Window Introgression Percentages\n",
    "    Win_intro_percent = {}\n",
    "    # Extract the columns into numpy arrays and round.\n",
    "    # Sorting makes iterating easier. Not changing any start positions. intro_starts is 'official' starting position\n",
    "    intro_starts = np.sort(np.round(true_intro_pos[:, 0]))\n",
    "    intro_stops = np.sort(np.round(true_intro_pos[:, 1]))\n",
    "    intro_sizes = np.sort(intro_stops - intro_starts)\n",
    "\n",
    "    # The index of the true introgression segment in start/stop/sizes\n",
    "    intro_index = 0\n",
    "    for key in Windows:\n",
    "        # if intro_index is the same as the number of true introgressed segments, we can end and assign the rest 0\n",
    "        if intro_index == intro_sizes.shape[0]:\n",
    "            Win_intro_percent[key] = 0.\n",
    "        else:\n",
    "            # Tracking indices\n",
    "            # integer starting and ending positions of the true introgressed segments\n",
    "            curr_start = int(intro_starts[intro_index])\n",
    "            curr_stop = int(intro_stops[intro_index])\n",
    "            # integer offset of curr_start and curr_stop from most recent window\n",
    "            curr_start_mod = int(intro_starts[intro_index] % 500)\n",
    "            curr_stop_mod = int(intro_stops[intro_index] % 500)\n",
    "            # current window that contains the beginning or end of the current segment\n",
    "            curr_start_window = int(((curr_start - curr_start_mod) / 500) + 1)\n",
    "            curr_stop_window = int(((curr_stop - curr_stop_mod) / 500) + 1)\n",
    "            # boolean that tracks whether the segment falls completely within a window (exception)\n",
    "            tiny_intro = curr_stop - curr_start < 500\n",
    "            # skips windows that come before the current start window\n",
    "            if key < curr_start_window:\n",
    "                Win_intro_percent[key] = 0.\n",
    "            elif key == curr_start_window:\n",
    "                # If the introgressed segment is less than 500, we need to do a special case to find the percentage\n",
    "                if tiny_intro:\n",
    "                    Win_intro_percent[key] = (curr_stop - curr_start) / 500\n",
    "                    # since this counts as a whole segment, we have to tick the index to seach for the next segment\n",
    "                    intro_index += 1\n",
    "                else:  # normal case, the true introgressed segment is over 500 base pairs long\n",
    "                    # calculates the % of the window that is covered by the segment from curr_start to the window's end\n",
    "                    Win_intro_percent[key] = (Windows[key][1] - curr_start) / 500\n",
    "            # In the middle of the introgressed segment, so each window is 100% covered\n",
    "            elif curr_start_window < key < curr_stop_window:\n",
    "                Win_intro_percent[key] = 1.\n",
    "            # In the last window containing the segment. It should be partially introgressed.\n",
    "            elif key == curr_stop_window:\n",
    "                # calculates the % of the window that is covered by the segment from the window's start to curr_stop\n",
    "                Win_intro_percent[key] = (curr_stop - Windows[key][0]) / 500\n",
    "                # since we found the stop window of a large segment, we can move onto the next segment, if any\n",
    "                intro_index += 1\n",
    "                # check to make sure that we record the same number of windows as there are segments\n",
    "                if intro_index > intro_sizes.shape[0]:\n",
    "                    print(\"ERROR: Recorded more windows than there are segments\")\n",
    "                    break\n",
    "            else:  # Error check\n",
    "                print(\"----------------------\")\n",
    "                print(\"ERROR: bug in key iteration for calculation of introgression percentages\")\n",
    "                print(\"----------------------\")\n",
    "                break\n",
    "\n",
    "    return Win_intro_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89443058-b35a-41f2-9ba2-7fc5380c5f49",
   "metadata": {},
   "source": [
    "---\n",
    "### `logsum()`\n",
    "#### Purpose: \n",
    "`logsum()` takes the numpy builtin function `numpy.logaddexp()` and expands its usage to multidimensional arrays. `numpy.logaddexp()` is used to calculate the logarithm of the sum of exponentiations of the inputs. This is useful in statistical methodologies where the calculated probabilites of events become so small they exceed the range of floating point numbers and the computer loses information by rounding them to zero.\n",
    "\n",
    "In this model, some derived values can be smaller than 1*10^-130.\n",
    "\n",
    "In cases like these,  calculation values are stored as the logarithm of the true probability. `logaddexp()` allows such probabilities to be added, as in the format `log(exp(arr1) + exp(arr2))`. \n",
    "\n",
    "`logsum()` is a more flexible version which can take in multidimensional arrays as valid input by stringing all data into a one-dimensional array by appending rows one after another. `logaddexp()` only typically works on a 1-dimensional array `[1, 2, 3, 4]`, but `logsum()` accounts for the case of multiple dimensions by converting the input into the 1-D format that `logaddexp()` can recognize: for example, by convering the array `[[1, 2], [3, 4]]` into the proper dimensions before `logaddexp()` is called. `logsum()` can still take in 1-D arrays as input.\n",
    "\n",
    "#### Input:\n",
    "- `array`: a numpy array, either of one or multiple dimensions.\n",
    "\n",
    "#### Output:\n",
    "- `sum`: the sum of log probabilities within the array, in log form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "267dee17-79ba-4f6b-9a6e-cc6909548edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsum(array):\n",
    "    # If the array is of multiple dimensions, it is 'flattened' along one dimension\n",
    "    if len(array.shape) > 1:\n",
    "        vec = np.reshape(array, (np.product(array.shape),))\n",
    "    else:\n",
    "        vec = array\n",
    "    # the recurrence relation has to include a base case\n",
    "    # before the sum is initialized the base case is negative infinity,\n",
    "    # which has an underlying probability of zero from a logaddexp perspective\n",
    "    sum = np.NINF\n",
    "    for num in vec:\n",
    "        sum = logaddexp(sum, num)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b840b9c7-cf2c-4bb1-8d29-f0e7d0c3e2fa",
   "metadata": {},
   "source": [
    "---\n",
    "### `calc_alpha()`\n",
    "\n",
    "#### Purpose:\n",
    "In the context of a HMM, the forward variable, or $\\alpha$, gives the probability of being in a certain state after observing some prefix of the emission sequence. A prefix refers to some number $t$ characters starting from the beginning of the observed sequence.\n",
    "\n",
    "Starting by having \"seen\" none of these characters and iteratively building on these probabilities, the alpha matrix answers the question: \"What is the probability that we will be in each state after having seen $t$ characters of the observed sequence?\" `calc_alpha()` creates this matrix so that the forward variable is calculated for all positions in the observed sequence.\n",
    "\n",
    "#### Input:\n",
    "- `A`: a 2x2 array of state transition probabilities\n",
    "- `B`: a 2x2 array of observation emission probabilities\n",
    "- `pi`: a 2x1 arry of initial state probabilities\n",
    "- `Ob`: a string representing the observed sequence (binary-encoded numbers indexed to labels: 0=\"N\", 1=\"C\")\n",
    "- `N`: the number of states (in this case, 2: {Species, Introgressed})\n",
    "- `T`: the length of the observed sequence (set to 40,000)\n",
    "\n",
    "#### Output:\n",
    "- `alpha`: a matrix that stores the forward variable alpha, which is the probability of observing some prefix of length `t` of the emission sequence and being in some given state `j` at the end of the prefix. `alpha[t][j]` gives the probability of observing the first `t` characters of the sequencing and ending at state `j`. It has dimensions `(T+1) X N` because the first row represents the state after 0 prefix characters, which is the same as the initial distribution likelihood - found in `pi`.\n",
    "\n",
    "The following is a visual representation of the alpha matrix. The first row and first column are for labeling purposes only. Note that the values in the last row comprise the total probability of the observed sequence being produced by the HMM, and the matrix is filled from top to bottom.\n",
    "\n",
    "| Prefix Length | State 0 (ends in Species) | State 1 (ends in Introgressed) |\n",
    "| --- | --- | --- |\n",
    "| t=0 | P(first state is S) | P(first state is I) |\n",
    "| t=1 | P(ends at state S \\| seen 1 observation) | P(ends at state I \\| seen 1 observation) |\n",
    "| t=2 | P(ends at state S \\| seen 2 observations) | P(ends at state I \\| seen 2 observations) |\n",
    "...\n",
    "| T=40,000 | P(ends at state S \\| seen 40k observations) | P(ends at state I \\| seen 40k observations) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f4bb6d-1650-4070-8f92-bd769158a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alpha(A, B, pi, Ob, N, T):\n",
    "    \n",
    "    # Must be T+1 columns in the alpha matrix bc the top one is the state after 0 prefix characters\n",
    "    # This is the same as the initial distribution likelihood found in pi\n",
    "    alpha = np.zeros((T + 1, N))\n",
    "    # initialize the first row to be the initial distribution values\n",
    "    # represents the probabilities of being in some state (S/1st or I/2nd) before seeing any (t=0) observed emissions\n",
    "    alpha[0, :] = pi\n",
    "    \n",
    "    # Compute each row, starting with 2nd row. 1st row filled in last step.\n",
    "    # t counts the character number in the sequence.\n",
    "    for t in range(1, T + 1):\n",
    "        \n",
    "        # k stores the character of the previous observed emission\n",
    "        k = Ob[t - 1]\n",
    "        # Compute each column, starting with 1st (Species state) then 2nd (Introgression state)\n",
    "        for j in range(N):\n",
    "            \n",
    "            # Placeholder is set to negative infinity the first time each cell is encountered, resetting it.\n",
    "            # It stores a probability interpreted by logaddexp as zero when calculating the first logsum\n",
    "            lprob = np.NINF\n",
    "            # The i loop occurs in a single cell, the variable iterating over the states in the previously-calculated row\n",
    "            # Inside the cell, calculate the sum of probabilities (in log form) of the transitions from all possible\n",
    "            # previous states in time t-1 (the previous row) into the new state j.\n",
    "            # In this case, N=2, meaning there were 2 possible previous states that could have led to the current one\n",
    "            # This code answers: \"What is the probability that each possible scenario (previous state being S or I) led to\n",
    "            # our current state j?\" When the loop is finished, the value of the cell is set to the combination of those probabilities.\n",
    "            for i in range(N):\n",
    "                \n",
    "                # lp represents a sum of log probabilities:\n",
    "                # (forward variable at time t-1 for state i)\n",
    "                # + likelihood that last row's state i transitioned to this state j using the transition matrix A\n",
    "                # + the likelihood that state i emitted this observed character k using the emission matrix B\n",
    "                lp = alpha[t - 1][i] + A[i][j] + B[i][k]\n",
    "                # during the first iteration, lprob is reset as equal to lp, as lprob starts set to NINF\n",
    "                # the second time around, lp is recalculated and represents the probability that the current state j\n",
    "                # was reached from the Introgressed state. Now, calling logaddexp(lprob, lp) represents the sum of these:\n",
    "                # (prob we're in state j if the last state was S + prob we're in state j if the last state was I)\n",
    "                lprob = logaddexp(lprob, lp)\n",
    "                \n",
    "            # After the probabilities based on both of the cells in the previous row were treated and combined,\n",
    "            # the final number is set as the forward variable:\n",
    "            # the likelihood we observe prefix (...t) of the observe sequence and end up in state j\n",
    "            alpha[t][j] = lprob\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896243e8-c11a-46b1-903d-c525dcb627f0",
   "metadata": {},
   "source": [
    "---\n",
    "### `calc_beta()`\n",
    "\n",
    "#### Purpose:\n",
    "In the context of a HMM, the backward variable, or beta, gives the probability of being in a certain state `j` just before observing a suffix of the emission sequence of length `t`. A suffix refers to some number `t` of the last characters in the sequence. Starting by having \"seen\" none of these chraracters and building on its own probabilities in reverse order, the beta matrix answers the question: \"What is the probability of being in state `j` right before the last `T-t` characters of the observed sequence (where `T` is the length of the sequence)?\" `calc_beta()` creates this matrix so that the backward variable is calculated for all positions in the observed sequence.\n",
    "\n",
    "\n",
    "#### Input:\n",
    "- `A`: a 2x2 array of state transition probabilities\n",
    "- `B`: a 2x2 array of observation emission probabilities\n",
    "- `pi`: a 2x1 arry of initial state probabilities\n",
    "- `Ob`: a string representing the observed sequence (binary-encoded numbers indexed to labels: O=N, 1=C)\n",
    "- `N`: the number of states (in this case, 2: {Species, Introgressed})\n",
    "- `T`: the length of the observed sequence (set to 40,000)\n",
    "\n",
    "#### Output:\n",
    "- `beta`: a matrix that stores the backward variable beta, which is the probability of being in some given state `j` before observing some suffix of length `t` of the emission sequence. `beta[t][j]` gives the probability of being in state `j` before seeing a suffix of length `t`. There must be `T+1` columns in the beta matrix because the final row (which is filled first in the calculation) represents the state chances before 0 suffix characters have been observed. The initial state is assumed as given (prior probability = 100%), so its value is 1. \n",
    "\n",
    "The following is a visual representation of the beta matrix. The first row and first column are for labeling purposes only. Note that the values in the top row comprise the total probability of each state preceding the entire observed sequence, and the matrix is filled from bottom to top.\n",
    "\n",
    "| Suffix Length | State 0 (came from Species) | State 1 (came from Introgressed) |\n",
    "| --- | --- | --- |\n",
    "| t=0 | P(will see all 40k observations \\| after S) | P(will see all 40k observations \\| after I) |\n",
    "...\n",
    "| t=39,998 | P(will see last 2 observations \\| after S) | P(will see last 2 observations \\| after I) |\n",
    "| t=39,999 | P(will see last 1 observation \\| after S) | P(will see last 2 observation \\| after I) |\n",
    "| t=40,000 | P(will see last 0 observations \\| after S) | P(will see last 0 observations \\| after I) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e5fd2ef-d8f6-4a74-8a53-562459bf3a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_beta(A, B, Ob, N, T):\n",
    "    # Must be T+1 columns in the beta matrix because the bottom one is the state before a 0-character suffix\n",
    "    # This is given as 100% in the base case, so we still initialize the matrix to zeroes.\n",
    "    # This is because the underlying proability assumed by the logaddexp occurrence is 1 (log(1) = 0).\n",
    "    beta = np.zeros((T + 1, N))\n",
    "    \n",
    "    # Compute each row, starting with the 2nd from the bottom. The bottom row was filled out during initialization.\n",
    "    # t counts the position of the state relative to the sequence\n",
    "    for t in range(T - 1, -1, -1):\n",
    "        \n",
    "        # k stores the character just after (emitted by) the state being investigated\n",
    "        k = Ob[t]\n",
    "        # Compute each column, starting with 1st (Species state) then 2nd (Introgression state)\n",
    "        for j in range(N):\n",
    "            \n",
    "            # Placeholder is set to negative infinity the first time each cell is encountered, resetting it.\n",
    "            # It stores a probability interpreted by logaddexp as zero when calculating the first logsum\n",
    "            lprob = np.NINF\n",
    "            # The i loop occurs in a single cell, the variable iterating over the states in the previously-calculated row\n",
    "            # Inside the cell, calculate the sum of probabilities (in log form) of the transitions from all possible\n",
    "            # previous states in time t+1 (the previous/lower row) to the current row t.\n",
    "            # This code answers: \"What is the probability that each state was arrived at through the emission of\n",
    "            # the most recent suffix character k from our current state in column j and a subsequent transition\n",
    "            # from state j to i?\" When the loop is finished, the value of the cell is set to the combination of those probabilities.\n",
    "            for i in range(N):\n",
    "                \n",
    "                # lp represents a sum of log probabilities:\n",
    "                # (backward variable at time t+1 for state i)\n",
    "                # + likelihood that the lower row's state i transitioned to this state j using the transition matrix A\n",
    "                # + the likelihood that state i emitted this observed character k using the emission matrix B\n",
    "                lp = beta[t + 1][i] + A[j][i] + B[j][k]\n",
    "                # during the first iteration, lprob is reset as equal to lp, as lprob starts set to NINF\n",
    "                # the second time around, lp is recalculated and represents the probability that the current state j\n",
    "                # transitioned the Introgressed state. Now, calling logaddexp(lprob, lp) represents the sum of these:\n",
    "                # (prob we're in state j if the next state is S + prob we're in state j if the next state is I)\n",
    "                lprob = logaddexp(lprob, lp)\n",
    "                \n",
    "            # After the proababilities based on both of the cells in the lower row were treated and combined,\n",
    "            # the final number is set as the backward variable:\n",
    "            # the likelihood we observe suffix(t...) of the observed sequence as a result of state j\n",
    "            beta[t][j] = lprob\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7fe239-58ad-44fa-92fe-992a0ff35c74",
   "metadata": {},
   "source": [
    "___\n",
    "### `calc_xi()`\n",
    "\n",
    "#### Purpose:\n",
    "In the context of a HMM, the xi variable gives the probability of being in a certain state state `i` at time `t` and state `j` at time `t + 1`. One can imagine the xi matrix as leveraging the forward and backward variables to calculate the probabilities of a transition between all possible pairs of hidden states between every two positions in the observed sequence. The xi matrix answers the question: \"What is the probability that the state transition `i` to `j` occurred from position `t` to position `t + 1`?\"\n",
    "\n",
    "#### Input:\n",
    "- `A`: a 2x2 array of state transition probabilities\n",
    "- `B`: a 2x2 array of observation emission probabilities\n",
    "- `Ob`: a string representing the observed sequence (binary-encoded numbers indexed to labels: O=N, 1=C)\n",
    "- `N`: the number of states (in this case, 2: {Species, Introgressed})\n",
    "- `T`: the length of the observed sequence (set to 40,000)\n",
    "- `alpha`: the matrix containing the forward variable, calculated by `calc_alpha`\n",
    "- `beta`: the matrix containing the backward variable, calculated by `calc_beta`\n",
    "\n",
    "#### Output:\n",
    "- `xi`: a matrix where `xi[i][j][t]` gives the probability of being in state `i` at time `t` and transitioning to state `j` at time `t + 1`. and transitioning to state `j` at time `t`.\n",
    "\n",
    "The following is a visual representation of `xi`. The first row and first column are for labeling purposes only. `xi` is a three-dimensional matrix (2 X 2 X 40,000), so I've simplified it into a visual representation here. Each row corresponds to a different time or transition position between two adjacent observed characters, filled out from top to bottom (as with `alpha`). One can imagine the second table as the \"back side\" of `xi`, existing directly behind the front side in a stack, like a second sheet of paper. This model reflects how the matrix is instantiated. One can think of the whole data structure as a `NxN` (2x2) tall \"tower\" which is `T` (40,000) stories high. The inner loops will begin at coordinates `(0, 0)` on the \"top floor\" (T-level) and visit every \"room\" on that floor in a counterclockwise fashion, going down a floor when all four rooms have been evaluated. The \"top floor\" here is t=0, which represents the first state transition associated with the observed sequence. `Ob[t]` and `Ob[t+1]` here refer to the adjacent observations in the sequence at the transition position being analyzed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aee2a07-6089-4c04-a2c0-3611b104caff",
   "metadata": {},
   "source": [
    "`xi` (Front Side):\n",
    "\n",
    "| Transition | State S went to State S | State S went to State I |\n",
    "| :--- | :--- | :--- |\n",
    "| t=0 | P(S -> S \\| `Ob[0]` -> `Ob[1]`) | P(S -> I \\| `Ob[0]` -> `Ob[1]`) |\n",
    "...\n",
    "| t=39,997 | P(S -> S \\| `Ob[39,997]` -> `Ob[39,998]`) | P(S -> I \\| `Ob[39,997]` -> `Ob[39,998]`) |\n",
    "| t=39,998 | P(S -> S \\| `Ob[39,998]` -> `Ob[39,999]`) | P(S -> I \\| `Ob[39,998]` -> `Ob[39,999]`) |\n",
    "| t=39,999 | P(S -> S \\| `Ob[39,999]` -> end) | P(S -> I \\| `Ob[39,999]` -> end) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc283aed-fbf0-49d0-8a9d-62a278aed456",
   "metadata": {},
   "source": [
    "`xi` (Back Side):\n",
    "\n",
    "\n",
    "| Transition | State I -> State S | State I -> State I |\n",
    "| :--- | :--- | :--- |\n",
    "| t=0 | P(I -> S \\| `Ob[0]` -> `Ob[1]`) | P(I -> I \\| `Ob[0]` -> `Ob[1]`) |\n",
    "...\n",
    "| t=39,997 | P(I -> S \\| `Ob[39,997]` -> `Ob[39,998]`) | P(I -> I \\| `Ob[39,997]` -> `Ob[39,998]`) |\n",
    "| t=39,998 | P(I -> S \\| `Ob[39,998]` -> `Ob[39,999]`) | P(I -> I \\| `Ob[39,998]` -> `Ob[39,999]`) |\n",
    "| t=39,999 | P(I -> S \\| `Ob[39,999]` -> end) | P(I -> I \\| `Ob[39,999]` -> end) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d0d777d-5c40-4d4b-9a3f-dbd09b44ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_xi(A, B, Ob, N, T, alpha, beta):\n",
    "    # Must be T columns in the xi matrix because there are T-1 transitions between observed characters,\n",
    "    # plus one state change from the state that emitted the last character to final state.\n",
    "    xi = np.zeros((T, N, N))\n",
    "    \n",
    "    # Compute each 2x2 row or \"floor\" of the matrix from top to bottom. t=0 represents the first transition between observations\n",
    "    for t in range(T):\n",
    "        k = Ob[t]\n",
    "        lp_traverse = np.zeros((N, N))\n",
    "        \n",
    "        # These loops will circle each \"floor\" and calculate each cell at the [i, j]th coordiante of that floor based\n",
    "        # on the corresponding alpha and beta matrix positions and the transition and emission matrices\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                \n",
    "                # lp, or the probability of this transition, is equal to the sum of\n",
    "                # P(getting to this state)\n",
    "                # P(making this transition)\n",
    "                # P(emitting this character)\n",
    "                # P(going to the end)\n",
    "                lp = (\n",
    "                        alpha[t][i]\n",
    "                        + A[i][j]\n",
    "                        + B[i][k]\n",
    "                        + beta[t + 1][j]\n",
    "                )\n",
    "                lp_traverse[i][j] = lp\n",
    "\n",
    "        # Each \"room\" on floor t has been calculated. Now that we have the values of all four cells, we can calculate\n",
    "        # the total probability of all cases on the top floor as the sum of logarithm probabilities within it.\n",
    "        # When the \"floor\" loop is over, this next step \"subtracts the logs\" (divides the probabilities) of each cell\n",
    "        # by the total probability of floor T.\n",
    "        # Normalize the probability for this time step (divide by P(O|lambda))\n",
    "        xi[t, :, :] = lp_traverse - logsum(lp_traverse)\n",
    "    return xi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96fd97d-ba81-4e36-b849-6c57180e70f6",
   "metadata": {},
   "source": [
    "---\n",
    "### `calc_gamma`\n",
    "\n",
    "#### Purpose:\n",
    "In the context of a HMM, the gamma variable gives the probability of being in a certain state state `i` at time `t`. This is the final variable in the workflow, as it gives the probability of Human/Neanderthal ancestry for any locus. The gamma variable answers the question: \"What is the probability that the observed locus at time `t` was a result of hidden state ancestry `i`?\"\n",
    "\n",
    "#### Input:\n",
    "- `xi`: the matrix containing the xi variable, calculated by `calc_xi`\n",
    "- `N`: the number of states (in this case, 2: {Species, Introgressed})\n",
    "- `T`: the length of the observed sequence (set to 40,000)\n",
    "\n",
    "#### Output:\n",
    "- `gamma`: a matrix where `gamma[t][i]` gives the probability of being in state `i` at time `t`.\n",
    "\n",
    "\n",
    "\n",
    "The following is a visual representation of `gamma`. The first row and first column are for labeling purposes only. Since hidden state 1 (Introgressed) refers to a likely Neanderthal ancestry, we take the right column `gamma[t][1]` of this matrix as the HMM's guess that the hidden state at this location in the sequence is a result of Neanderthal introgression. `Ob[t]` refers to the observation in the sequence at the locus being analyzed.\n",
    "\n",
    "\n",
    "| Observation (500-bp locus) | State 0 (Species) | State 1 (Introgressed) |\n",
    "| --- | --- | --- |\n",
    "| t=0 | P(`Ob[0]` \\| S) | **P(`Ob[0]` \\| I)** |\n",
    "| t=1 | P(`Ob[1]` \\| S) | **P(`Ob[1]` \\| I)** |\n",
    "| t=2 | P(`Ob[2]` \\| S) | **P(`Ob[2]` \\| I)** |\n",
    "...\n",
    "| t=40,000 | P(`Ob[39,999]` \\| S) | **P(`Ob[39,999]` \\| I)** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "313c166a-0445-48ff-8f45-bbd0e44879e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gamma(xi, N, T):\n",
    "    # Must be T columns in the gamma matrix because there are T observed loci\n",
    "    gamma = np.zeros((T, N))\n",
    "    \n",
    "    # Compute each row, starting with the first and going down. Each corresponds to a locus\n",
    "    for t in range(T):\n",
    "        \n",
    "        # Compute each column, starting with the Species state (i=0) and then the Introgressed state (i=1)\n",
    "        for i in range(N):\n",
    "            \n",
    "            # Sum up the probabilities for state i at this position t by combining all relevant instances\n",
    "            # where the hidden state could be i at time t\n",
    "            gamma[t][i] = logsum(xi[t, i, :])\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa7a89-1baa-4f45-a80b-95c06080e39d",
   "metadata": {},
   "source": [
    "---\n",
    "### `update_A()`\n",
    "\n",
    "#### Purpose:\n",
    "This function is used in the Baum-Welch algorithm in order to update the transition matrix based on the real distribution of probabilities that come from the `gamma` calculated by the last iteration of the model. The transition matrix `A[i][j]` is updated by finding the sum of all transitions from positions `i` to `j` (found with `xi`), and the update normalizes this matrix by the sum of the transitions out of state `i` (found with `gamma`). It is important to remember that the HMM does not \"know\" the true states and their transitions, it is updating its own parameters by observing the frequency of its *guesses* at the true states and adjusting according to probability.\n",
    "\n",
    "#### Input:\n",
    "- `N`: the number of states (in this case, 2: {Species, Introgressed})\n",
    "- `xi`: the matrix containing the xi variable, calculated by `calc_xi`\n",
    "- `gamma`: the matrix containing the gamma variable, calculated by `calc_gamma`\n",
    "\n",
    "#### Output:\n",
    "- `A`: an updated 2x2 transition probability matrix based on the prevalence of transitions between inferred states after analyzing the observed sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ca5737-bc4e-4979-a690-049b8c3ce26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_A(N, xi, gamma):\n",
    "    # Initialize a blank new transition matrix\n",
    "    A = np.zeros((N, N))\n",
    "    # Initialize the sum of all transitions out of i\n",
    "    trans_out = np.zeros(N)\n",
    "    \n",
    "    # for every state i in gamma (Species or Neanderthal)\n",
    "    for i in range(N):\n",
    "        # how many transitions out of state i were there\n",
    "        # summing probabilities because a confidence of 1 counts as 1 transition, 50% confidence counts as half, etc.\n",
    "        trans_out[i] = logsum(gamma[:, i])\n",
    "    \n",
    "    # for every starting state i in xi\n",
    "    for i in range(N):\n",
    "        # for every receiving state j in xi\n",
    "        for j in range(N):\n",
    "            # A (transition) [i][j] is the sum of all the transitions from i to j\n",
    "            # This normalized by the previously-calculated sum of the total number of inferred transitions from state i\n",
    "            A[i][j] = logsum(xi[:, i, j]) - trans_out[i]\n",
    "            \n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243da161-924a-46c5-aaa0-7a262eee4fc6",
   "metadata": {},
   "source": [
    "---\n",
    "### `update_B()`\n",
    "\n",
    "#### Purpose:\n",
    "This function is used in the Baum-Welch algorithm in order to update the emission matrix based on the real distribution of emissions from inferred true states that come from the `xi` calculated by the last iteration of the model. The transition matrix `A[i][j]` is updated by finding the sum of all transitions out of `i` when emission `k` is observed and dividing by the total number of transitions out of `i`.\n",
    "\n",
    "#### Input:\n",
    "- `Ob`: a string representing the observed sequence (binary-encoded numbers indexed to labels: O=N, 1=C)\n",
    "- `N`: the number of states (in this case, 2: {Species, Introgressed})\n",
    "- `M`: the number of possible observations (in this case, 2: {N (Not Consistent), C (Consistent)})\n",
    "- `T`: the length of the observed sequence (set to 40,000)\n",
    "- `xi`: the matrix containing the xi variable, calculated by `calc_xi`\n",
    "\n",
    "#### Output:\n",
    "- `B`: an updated 2x2 emission probability matrix based on the prevalence of emissions from inferred states after analyzing the observed sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "190000c5-9fdd-4ae3-9110-ebdb12cc31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_B(Ob, N, M, T, xi):\n",
    "    # Initialize a blank new emission matrix\n",
    "    B = np.zeros((N, M))\n",
    "    # For every state i\n",
    "    for i in range(N):\n",
    "        # Initialize the matrix of all emissions from state i\n",
    "        # ksum[k] is the sum of all i with k\n",
    "        ksum = np.zeros(M) + np.NINF\n",
    "        # for every observed locus t in the sequence\n",
    "        for t in range(T):\n",
    "            # set k to the observation at the current locus\n",
    "            k = Ob[t]\n",
    "            # for every state j\n",
    "            for j in range(N):\n",
    "                # find the sum of all emissions of k from state i when transitioning to each state j and add them\n",
    "                ksum[k] = logaddexp(ksum[k], xi[t, i, j])\n",
    "        # Normalize the sum of all emissions of k from that state i by the sum of all emissions at that position\n",
    "        ksum = ksum - logsum(ksum)\n",
    "        # Set the new emission matrix to the normalized probability of every type of emission k from state i\n",
    "        B[i, :] = ksum\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27882a2-966c-43fc-95a7-de5f20e073b2",
   "metadata": {},
   "source": [
    "---\n",
    "### `update_pi`\n",
    "\n",
    "#### Purpose:\n",
    "This function is used in the Baum-Welch algorithm in order to update the initial distribution matrix based on the inferred first true state that comes from the `gamma` calculated by the last iteration of the model. The initial distribution matrix `pi[i]` is updated by finding the probability of the first state being state `i` as calculated under the previous model's parameters.\n",
    "\n",
    "#### Input:\n",
    "- `N`: the number of states (in this case, 2: {Species, Introgressed})\n",
    "- `gamma`: the matrix containing the gamma variable, calculated by `calc_gamma`\n",
    "\n",
    "#### Output:\n",
    "- `pi`: an updated 1x2 initial distribution probability matrix based on the probability of true states at the first observed locus in the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66ce2349-421f-4202-8f7a-5d6133785e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteratively update pi\n",
    "def update_pi(N, gamma):\n",
    "    # Initialize a blank new initial distribution matrix\n",
    "    pi = np.zeros(N)\n",
    "    # for every state i\n",
    "    for i in range(N):\n",
    "        # The adjusted chances that a observed sequence will start on state i\n",
    "        # are set to the probability that the first locus was i in the last iteration of the model\n",
    "        pi[i] = gamma[0][i]\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08489d37-e0aa-479f-a818-a1b2002de383",
   "metadata": {},
   "source": [
    "---\n",
    "### `eval_accuracy` (Ignore performance measurement for now)\n",
    "\n",
    "#### Purpose:\n",
    "This function measures the performance of an HMM against true introgression positions.\n",
    "\n",
    "#### Input:\n",
    "- `true_windows`: numpy array of windows containing introgressed sites measured by percentage coverage. Some sites will have incomplete window edges.\n",
    "- `tested_HMM`: numpy gamma matrix returned from HMM. Represents likelihood of introgression at position. Should be pre-exponentiated (float probabilities not logs).\n",
    "- `normalized`: Boolean determining behavior of algorithm (default True). False will evaluate HMM correct \"guesses\" as they are presented: are they over the threshold or not? True will adjust the HMM \"guesses\", treating them as relative likelihoods: the highest scoring window is set to 1 and other probabilities are normalized accordingly, then evaluated in relation to the original threshold\n",
    "- `threshold`: float representing the level of certainty about a true state being introgressed that `gamma` must have in order for the inference to be counted as a guess\n",
    "\n",
    "#### Output:\n",
    "- `performance`: numpy array of floats `[false_pos_r, miss_rate, sensitivity, specificity]`\n",
    "In this context, a \"positive\" represents a locus that the HMM has inferred to be a result of introgression from Neanderthals above the confidence `threshold`. Whether or not that is true or false depends on the simulated ancestral history of that locus.\n",
    "- `false_pos_r`: float of \"false positive\" rate or (# false positivies / (# false positives + # true negatives)). It is the probability that a true negative will test positive given the model (false alarm).\n",
    "- `miss_rate`: float of \"false negative\" rate or (# false negatives / (# false negatives + # true positives)). It is the probability that a true positive will test negative given the model (this is expected to happen often, as true introgressed states rarely result in only Consistent-type genomic patterns within a 500 base pair window)\n",
    "- `sensitivity`: float of \"true positive\" rate or (# true positives / (# true positives + # false negatives)). It is the probability that a true positive will test positive given the model.\n",
    "- `specificity`: float aof \"true negative\" rate or (# true negatives / (# true negatives + # false positives)). It is the probability that a true negative will test negative given the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb7b4b6c-3cfc-45ea-9bb7-14ca80488669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(true_windows, tested_HMM, normalized=True, threshold=.9):\n",
    "    # matrix of windows containing introgressed sites (1. = 100% coveragechira\n",
    "    tiw = true_windows\n",
    "    # takes the second column of gamma, which measures the likelihood of Neanderthal ancestry\n",
    "    gamma = tested_HMM[:, 1]\n",
    "\n",
    "    # performance values preset to -1 to easily show errors\n",
    "    false_pos_r = -1\n",
    "    miss_rate = -1\n",
    "    sensitivity = -1\n",
    "    specificity = -1\n",
    "\n",
    "\n",
    "    # If we need to normalize, change values of gamma such that the highest-scoring site is set to 100%\n",
    "    if normalized:\n",
    "        # Find the value of the highest-scoring site in gamma\n",
    "        max_prob = np.amax(gamma)\n",
    "        # Multiply every probability in gamma (including the highest-scoring site) by 1/max_prob\n",
    "        gamma = gamma * (1 / max_prob)\n",
    "\n",
    "    # Compare gamma and tiw to see if they have the same number of elements (windows)\n",
    "    if len(tiw) == len(gamma):\n",
    "\n",
    "        fp = 0  # number of false positives\n",
    "        fn = 0  # number of false negatives\n",
    "        tp = 0  # number of true postivies\n",
    "        tn = 0  # number of true negatives\n",
    "\n",
    "        # loop through gamma and record the number of true/false positives/negatives\n",
    "        for w in range(len(tiw)):\n",
    "            # Underlying window is partially or completely introgressed\n",
    "            if 0 < tiw[w] <= 1.:\n",
    "                # true positive\n",
    "                if gamma[w] >= threshold:\n",
    "                    tp += 1 # tiw[w]\n",
    "                # false negative\n",
    "                else:\n",
    "                    fn += 1 # tiw[w]\n",
    "            # Underlying window is not 100% introgressed\n",
    "            elif tiw[w] == 0:\n",
    "                # false positive\n",
    "                if gamma[w] >= threshold:\n",
    "                    fp += 1 # tiw[w]\n",
    "                # true negative\n",
    "                else:\n",
    "                    tn += 1 # tiw[w]\n",
    "            # something went wrong and tiw shows a value below zero or above 1\n",
    "            else:\n",
    "                print(\"ERROR in eval: window shows introgression percentage below zero or above 1\")\n",
    "\n",
    "        # check at the end to see if tp + tn + fp + fn == number of windows\n",
    "        if tp + tn + fp + fn != len(tiw):\n",
    "            print(\"ERROR in eval: true positives and true negatives do not sum to the number of windows\")\n",
    "            print(tp + tn + fp + fn)\n",
    "\n",
    "        # Calculate rates for performance\n",
    "        print(\"#tp: \" + str(tp) + \"\\t#tn: \" + str(tn), \"\\t#fp: \" + str(fp), \"\\t#fn: \" + str(fn))\n",
    "        false_pos_r = fp / (fp + tn)\n",
    "        miss_rate = fn / (fn + tp)\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR IN EVAL: C column of gamma and true introgressed window array have different number of windows\")\n",
    "\n",
    "    performance = np.array([false_pos_r, miss_rate, sensitivity, specificity])\n",
    "    return performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80fa751-4d8d-4387-82bb-88e982417e45",
   "metadata": {},
   "source": [
    "### Not Included Because They Contain More than Other Functions: `extract_O()` and `hmm()`\n",
    "- `extract_O()` (contains `genotype_matrix_windows()` and `calc_window_intro_percent()`)\n",
    "- `hmm()` (contains everything else)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d956d0d3-da16-404e-aa8e-5032aee2635a",
   "metadata": {},
   "source": [
    "---\n",
    "# Example Workflow Using Simulated Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0becc5-9c04-44b2-b324-62c05603ee94",
   "metadata": {},
   "source": [
    "#### Types of Simulated Data\n",
    "- var_pos: an nparray of variant positions. Each variant is represented by a new row of the array, and the cell value represents its position in the genome in base pairs\n",
    "- pol_geno_mat: NOT polarized - in simulations ancestral alleles are known for sure\n",
    "\n",
    "`position\t\tnum_missing_calls\t\thaps_with_missing_calls\t\tlocus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "557a3cf0-9e78-439e-9cae-681ce3a10117",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_pos = np.loadtxt('../sim_example/rep_id_1_var_pos.csv.gz', delimiter=',')\n",
    "pol_geno_mat = np.loadtxt('../sim_example/rep_id_1_geno_mat.csv.gz', dtype=int,delimiter=',')\n",
    "true_intro_pos = np.loadtxt('../sim_example/rep_id_1_intro_pos.csv.gz', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96837c5b-faf4-41a5-9a4d-4be56ff5468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the window structure and bin variant positions\n",
    "Windows_pos = genotype_matrix_windows(var_pos, pol_geno_mat, window_size=500, sequence_length=20_000_000)\n",
    "# Generate another dictionary that contains the true introgression positions\n",
    "Windows_true = calc_window_intro_percent(Windows_pos, true_intro_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5d906ee-a73a-4897-8824-588bd61fcdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize observed sequence\n",
    "obs_seq = []\n",
    "# Define what C, a pattern consistent with introgression, would look like\n",
    "# (Polarized genotype matrix order is [AFR1, AFR2, EUR, NEAN] where 0 represents ancestral alleles\n",
    "c_pattern = np.array([0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da463de3-3538-483b-8770-e05addeeb257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each window by key\n",
    "for key in Windows_pos:\n",
    "    # Extract the positions and variants for the window\n",
    "    window_vals = Windows_pos[key]\n",
    "    # Print the tracker\n",
    "    # print('there are {0} variants in window {1}'.format(len(window_vals[2:]), key))\n",
    "    # If there are variants in the window: (NOTE: Windows with 1 variant are still counted!!)\n",
    "    # Typically Window[key] gives [start, stop]. If there are 1 or more variants then the len(value)>2\n",
    "    if len(window_vals) > 2:\n",
    "        # Extract variable positions in that window. [2:] excludes start pos and end pos\n",
    "        variants = np.asarray(window_vals[2:], dtype=np.int32)\n",
    "        # Subset the genotype matrix for that window.\n",
    "        window_geno_mat = pol_geno_mat[variants, :]\n",
    "        # print(window_geno_mat)\n",
    "        # Define what C matrix would look like given an arbitrary number of variants.\n",
    "        c_mat = np.tile(c_pattern, (window_geno_mat.shape[0], 1))\n",
    "        # If the C matrix is equal to the windowed matrix declare it consistent.\n",
    "        if np.array_equal(c_mat, window_geno_mat):\n",
    "            # print('C')\n",
    "            obs_seq.append('C')\n",
    "        # Else declare the window non-consistent.\n",
    "        else:\n",
    "            # print('N')\n",
    "            obs_seq.append('N')\n",
    "    # If there are no variants in the window declare in non-consistent.\n",
    "    else:\n",
    "        # print('N')\n",
    "        obs_seq.append('N')\n",
    "# Convert the observation sequence list to an array.\n",
    "obs_seq_array = np.asarray(obs_seq)\n",
    "\n",
    "# print('there are {0} many consistent observations'.format(np.count_nonzero(obs_seq_array == 'C')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ec47b-891e-4f9a-9a35-9e232efd7915",
   "metadata": {},
   "source": [
    "### Manually performing `hmm()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "257f6ee2-325c-4743-8a46-dbb3d78ed13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING UP PRUFER PARAMETERS\n",
    "s = .0005 # Ancestral switch rate\n",
    "p = 0.01 # Prior probability for archaic ancestry at any locus (initial distribution)\n",
    "u = 0.99 # Prior probability of archaic ancestry conditional on all SNPs in the window being of state \"C\"\n",
    "threshold = .9 # Probability cutoff for HMM's \"guess\" at a true state (must be above 90%)\n",
    "N = 2 # State space (State 0 = 'S' (Species/sapiens), State 1 = 'I' (Introgressed/neandertalensis))\n",
    "M = 2 # Observation space (Observation 0 = 'N' (not consistent), Observation 1 = 'C' (consistent))\n",
    "convergence_threshold = 0.01 # Log-likelihood convergence threshold - used to auto-end Baum-Welch\n",
    "# Setting up other parameters\n",
    "normalized = False # Does not normalize results based on relative probability\n",
    "optimization_limit = 100 # Primary Baum-Welch adjustment parameter, to make sure it doesn't overfit\n",
    "# Note that the Naive HMM is counted as BW#=0, so an optimization_limit of 20 will result in 19 optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57b07704-acf5-49d4-bb87-21005a64f278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING\n",
    "T = len(obs_seq_array) # length of the sequence (40,000)\n",
    "observation_letters = ['N', 'C'] # index letter observations for future use\n",
    "# Ob is the same as obs_seq_array, but with 'N' replaced by 0 and 'C' replaced by 1 for quick reference\n",
    "Ob = [observation_letters.index(label) for label in obs_seq_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29b75158-2ea6-449f-8df6-385011e15d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING UP HMM\n",
    "# All calculations are done in log-space to prevent point-underflows\n",
    "\n",
    "# Transition Probabilities (2x2)\n",
    "A = np.array(((1 - s, s), (s, 1 - s)))\n",
    "lp_A = np.log(A)\n",
    "\n",
    "# Emission Probabilities (2x2)\n",
    "B = np.array(((u, 1 - u), (1 - u, u)))\n",
    "lp_B = np.log(B)\n",
    "\n",
    "# Initial State Distribution (2x1)\n",
    "pi = np.array((1 - p, p))\n",
    "lp_pi = np.log(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ac546-d3bf-4b44-8d31-18337b118a87",
   "metadata": {},
   "source": [
    "---\n",
    "#### Sanity Check: visualizing HMM parameter matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9cb0ace-b696-4a60-a222-ffaa63999968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca138e55-b716-43c1-8711-180b69dcfe4f",
   "metadata": {},
   "source": [
    "| A | Species | Introgressed |\n",
    "| :--- | --- | --- |\n",
    "| Species | 99.95% | 0.05% |\n",
    "| Introgressed | 0.05% | 99.95% |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7881b6c-265f-465e-beb7-e5fccab203a8",
   "metadata": {},
   "source": [
    "| B | N | C |\n",
    "| :--- | --- | --- |\n",
    "| Species | 99% | 1% |\n",
    "| Introgressed | 1% | 99% |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb92321-3082-4d60-ae7b-c8fbc2c0f606",
   "metadata": {},
   "source": [
    "| pi | Species | Introgressed |\n",
    "| :--- | --- | --- |\n",
    "| Start | 99% | 1% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60d588b6-74bf-4b36-8f59-05a5c04487b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.995e-01 5.000e-04]\n",
      " [5.000e-04 9.995e-01]]\n",
      "---\n",
      "[[0.99 0.01]\n",
      " [0.01 0.99]]\n",
      "---\n",
      "[0.99 0.01]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Checking Work:\n",
    "print(A)\n",
    "print('---')\n",
    "print(B)\n",
    "print('---')\n",
    "print(pi)\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3f0251-c69e-41d9-89c0-91fe9772a9d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ad54ee9-38f7-45a6-aa7e-05a4e4481e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40001, 2) (40001, 2) (40000, 2, 2) (40000, 2)\n"
     ]
    }
   ],
   "source": [
    "# RUNNING PRUFER'S NAIVE HMM\n",
    "# Initialize log-likelihood trackers\n",
    "logP_old = np.NINF\n",
    "alpha = calc_alpha(lp_A, lp_B, lp_pi, Ob, N, T)\n",
    "logP_new = logsum(alpha[T, :])\n",
    "beta = calc_beta(lp_A, lp_B, Ob, N, T)\n",
    "xi = calc_xi(lp_A, lp_B, Ob, N, T, alpha, beta)\n",
    "gamma = calc_gamma(xi, N, T)\n",
    "                  \n",
    "print(alpha.shape, beta.shape, xi.shape, gamma.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63321c-3e73-4afa-b5e3-d77e8684d0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization count 1\n",
      "Improvement of 9.047120340261799e+22 from last model\n",
      "Optimization count 2\n",
      "Improvement of 1.295197920741631 from last model\n",
      "Optimization count 3\n",
      "Improvement of 2.3191669296742026 from last model\n",
      "Optimization count 4\n",
      "Improvement of 9.568799392353593 from last model\n",
      "Optimization count 5\n",
      "Improvement of 63.47645281472657 from last model\n",
      "Optimization count 6\n",
      "Improvement of 145.39085829567338 from last model\n",
      "Optimization count 7\n",
      "Improvement of 70.87583523488794 from last model\n",
      "Optimization count 8\n",
      "Improvement of 26.183863279011334 from last model\n",
      "Optimization count 9\n",
      "Improvement of 14.416811020227078 from last model\n",
      "Optimization count 10\n",
      "Improvement of 11.171369758223577 from last model\n",
      "Optimization count 11\n",
      "Improvement of 11.042451412787731 from last model\n",
      "Optimization count 12\n",
      "Improvement of 13.979133884167403 from last model\n",
      "Optimization count 13\n",
      "Improvement of 25.288762056991537 from last model\n",
      "Optimization count 14\n",
      "Improvement of 78.21939897910431 from last model\n",
      "Optimization count 15\n",
      "Improvement of 392.26904434469554 from last model\n",
      "Optimization count 16\n",
      "Improvement of 1447.5831457278516 from last model\n",
      "Optimization count 17\n",
      "Improvement of 1866.7691323250149 from last model\n"
     ]
    }
   ],
   "source": [
    "# RUNNING BAUM-WELCH OPTIMIZATION\n",
    "\n",
    "# Initializing a dicitonary of gammas\n",
    "# This will allow the comparison of estimated likelihoods over rounds of B-W\n",
    "# It has the structure (current optimization round -> gamma matrix at that round)\n",
    "All_gammas = {}\n",
    "\n",
    "# Begin the Baum-Welch loop\n",
    "optimization_count = 0\n",
    "# Iterate until convergence is reached between results, performance decreases, or the hard cap is met\n",
    "while logP_new - logP_old > convergence_threshold and optimization_count < optimization_limit:\n",
    "\n",
    "    # calculate variables / fill out matrices\n",
    "    bw_alpha = calc_alpha(lp_A, lp_B, lp_pi, Ob, N, T)\n",
    "    bw_beta = calc_beta(lp_A, lp_B, Ob, N, T)\n",
    "    bw_xi = calc_xi(lp_A, lp_B, Ob, N, T, bw_alpha, bw_beta)\n",
    "    bw_gamma = calc_gamma(bw_xi, N, T)\n",
    "\n",
    "    # recording optimization count / performance progress\n",
    "    if optimization_count >= 1:\n",
    "        print(\"Optimization count \" + str(optimization_count))\n",
    "        print(\"Improvement of \" + str(np.exp(logP_new - logP_old)) + \" from last model\")\n",
    "        All_gammas[optimization_count] = bw_gamma\n",
    "    # we set it to just run once\n",
    "    elif optimization_count == 0:\n",
    "        All_gammas[optimization_count] = gamma\n",
    "\n",
    "    # once variables have been calculated and progress displayed, the counter ticks up\n",
    "    optimization_count += 1\n",
    "\n",
    "    # update lambda, the underlying assumptions of the HMM\n",
    "    new_A = update_A(N, bw_xi, bw_gamma)\n",
    "    new_B = update_B(Ob, N, M, T, bw_xi)\n",
    "    new_pi = update_pi(N, bw_gamma)\n",
    "\n",
    "    # recalculate the forward variable (alpha matrix) from the new lambda\n",
    "    bw_alpha = calc_alpha(new_A, new_B, new_pi, Ob, N, T)\n",
    "\n",
    "    # continue iterating only if performance improves, or\n",
    "    # the likelihood of seeing this sequence given this new HMM increases\n",
    "    logP_old = logP_new\n",
    "    # compares last two probabilities of the alpha matrix (%chance of seeing the complete prefix)\n",
    "    # to the old log-probability of seeing the complete prefix given the HMM parameters\n",
    "    if logsum(bw_alpha[T, :]) > logP_old:\n",
    "        lp_A, lp_B, lp_pi = new_A, new_B, new_pi\n",
    "        logP_new = logsum(bw_alpha[T, :])\n",
    "        \n",
    "        \n",
    "print(len(All_gammas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4874508b-e348-421c-a848-2c8c62b5ead0",
   "metadata": {},
   "source": [
    "---\n",
    "#### Generating Results Table\n",
    "Results is a numpy array that will be filled and exported with all the results of a single rep id.\n",
    "\n",
    "Note that since this is a numpy array, Observation Labels are indicated with 0 or 1 instead of N and C, respectively. X in the columns to the right represent the index of `All_gammas`, or the number of optimization steps run on that model. It is expected that inference becomes more accurate as one moves to the right.\n",
    "\n",
    "| Window Start Position | Window Stop Position | True Introgression % | Observation Label | BW{X} gamma | BW{X+1} gamma |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 500 | 0 | 0 | .01 | .01 |\n",
    "| 500 | 1000 | .2 | 0 | 0.05 | 0.1 |\n",
    "| 1000 | 1500 | 1 | 1 | .5 | .99 |\n",
    "| 1500 | 2000 | .6 | 0 | .05 | .0.1 |\n",
    "...\n",
    "| 39,500 | 40,000 | 0 | 0 | .01 | .01 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d02e97-837e-49cb-a498-5c786c28edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_windows = len(Windows_pos)\n",
    "# There must be an extra column added to show observation labels\n",
    "results = np.zeros((num_windows, optimization_limit + 4))\n",
    "# The observations are found in column index 3\n",
    "observation_col_index = 3\n",
    "\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c646be11-6f7d-474a-85bf-08f15a2312fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECORDING RESULTS\n",
    "for key in Windows_pos:\n",
    "    # initializing starts\n",
    "    results[key-1][0] = Windows_pos[key][0]\n",
    "    # initializing stops\n",
    "    results[key-1][1] = Windows_pos[key][1]\n",
    "    # initializing true introgression percentages\n",
    "    results[key-1][2] = Windows_true[key]\n",
    "    # indicating window labels (1 = C, 0 = N)\n",
    "    results[key-1][3] = Ob[key-1]\n",
    "# iterating through all baum-welch gamma matrices\n",
    "for g in range(0, optimization_limit):\n",
    "    # for each particular window position in gamma, what is the percentage change of introgression?\n",
    "    for w in range(0, num_windows):\n",
    "        results[w][g + 4] = np.exp(All_gammas[g][w][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df655c3-2aed-46f4-bd87-884791a04100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "#     np.savetxt('/Users/briankirz/Documents/GitHub/mentee_research/kirz/site_pattern_hmm/hmm_code/workflow_results.csv.gz', \n",
    "np.savetxt('/Users/briankirz/Documents/GitHub/mentee_research/kirz/site_pattern_hmm/hmm_code/workflow_results.csv.gz', \n",
    "           results,\n",
    "           fmt='%1.3f',\n",
    "           delimiter='\\t',\n",
    "           newline='\\n',\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d6c771-2d50-463f-87e5-cf89c11ad44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the results into a text file\n",
    "with gzip.open('workflow_results.csv.gz', 'rb') as f_in:\n",
    "    with open('workflow_results.txt', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "# Optional: Change the textfile to reflect 'N' or 'C'\n",
    "# instead of 0 or 1 in the Observed label column for better searching\n",
    "with open('workflow_results.txt', 'r') as f_in:\n",
    "    with open('workflow_results_CN.txt', 'w') as f_out:\n",
    "        lines = f_in.readlines()\n",
    "        for line in lines:\n",
    "            split_line = re.split(r'\\t', line)\n",
    "            # initialize new line with first element of original \n",
    "            newline = split_line[0]\n",
    "            # if the current column index is the same as the observation\n",
    "            # we exclude the first element because it doesn't fit the \\t recurrence\n",
    "            for column in range (1, len(split_line)):\n",
    "                if column == observation_col_index:\n",
    "                    # replace the element with C\n",
    "                    if split_line[observation_col_index] == '1.000':\n",
    "                        newline += ('\\tC')\n",
    "                    # replace the element with N\n",
    "                    elif split_line[observation_col_index] == '0.000':\n",
    "                        newline += ('\\tN')\n",
    "                    else:\n",
    "                        print(\"ERROR: value in observation column not 1 or 0\")\n",
    "                # copy all other columns normally\n",
    "                else:\n",
    "                    newline += ('\\t'+split_line[column])\n",
    "            # copy complete new line in new file\n",
    "            f_out.write(newline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cffcbf1-a51c-4a1d-9d62-73c3ae9425a2",
   "metadata": {},
   "source": [
    "---\n",
    "#### Code example with streamlined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53df71c6-467e-490b-b8ff-8627998f4cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization count 1\n",
      "Improvement of 52.859318558500036 from last model\n",
      "Optimization count 2\n",
      "Improvement of 0.25866351802301324 from last model\n",
      "Optimization count 3\n",
      "Improvement of 0.8412080391558447 from last model\n",
      "Optimization count 4\n",
      "Improvement of 2.258507742250231 from last model\n",
      "#tp: 0\t#tn: 39660 \t#fp: 0 \t#fn: 340\n",
      "#tp: 0\t#tn: 39660 \t#fp: 0 \t#fn: 340\n",
      "#tp: 0\t#tn: 39660 \t#fp: 0 \t#fn: 340\n",
      "#tp: 0\t#tn: 39660 \t#fp: 0 \t#fn: 340\n",
      "#tp: 0\t#tn: 39660 \t#fp: 0 \t#fn: 340\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sh hmm.sh ../sim_example/rep_id_1_var_pos.csv.gz ../sim_example/rep_id_1_geno_mat.csv.gz ../sim_example/rep_id_1_intro_pos.csv.gz hmm_function_results.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26671468-12e1-474c-81f3-7d261e7db0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both files are identical!\n"
     ]
    }
   ],
   "source": [
    "# Check if the two output files are the same\n",
    "# reading files\n",
    "f1 = open('/Users/briankirz/Documents/GitHub/mentee_research/kirz/site_pattern_hmm/hmm_code/hmm_function_results_CN.txt', \"r\")  \n",
    "f2 = open('/Users/briankirz/Documents/GitHub/mentee_research/kirz/site_pattern_hmm/hmm_code/workflow_results_CN.txt', \"r\")  \n",
    "  \n",
    "i = 0\n",
    "\n",
    "# Boolean tracking identity\n",
    "identical = True\n",
    "\n",
    "for line1 in f1:\n",
    "    i += 1\n",
    "      \n",
    "    for line2 in f2: \n",
    "        # matching line1 from both files\n",
    "        if line1 != line2:  \n",
    "            identical = False\n",
    "            print(\"Line \", i, \":\")\n",
    "            # else print that line from both files\n",
    "            print(\"\\tFile 1:\", line1, end='')\n",
    "            print(\"\\tFile 2:\", line2, end='')\n",
    "        break\n",
    "  \n",
    "# closing files\n",
    "f1.close()                                       \n",
    "f2.close()  \n",
    "\n",
    "if identical:\n",
    "    print(\"Both files are identical!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e772d5e-60fb-4d3c-917b-6d84bca9c30c",
   "metadata": {},
   "source": [
    "---\n",
    "### Workflow function\n",
    "\n",
    "#### Done step by step\n",
    "\n",
    "#### Once as a large function, compare its output to"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

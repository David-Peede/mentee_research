{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "500b0181-0648-40fd-9f0a-e2f8ae1b0cc9",
   "metadata": {},
   "source": [
    "# Running a Hidden Markov Model with the Baum-Welch Algorithm on Simulated Ancestral Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b85fb-9cca-45c4-a801-2b4e4e504cab",
   "metadata": {},
   "source": [
    "---\n",
    "## Purpose of Guide\n",
    "Using simulated genomic data of human populations, this Hidden Markov Model infers the likelihood of introgression from an archaic population at each locus on a simulated genome. It further uses the Baum-Welch Algorithm to optimize this detection.\n",
    "In this guide, I'll walk through how to run my HMM from start to finish on a single pre-generated rep id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca41abf7-f7c1-4119-b4ec-1b73bb91f0aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sys' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Print versions of our libraries.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msys\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, time\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sys' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "# Import packages.\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Print versions of our libraries.\n",
    "print('sys', sys.__version__)\n",
    "print('numpy', np.__version__)\n",
    "print('time', time.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e41d884-0ec3-4a89-b8a7-357dc3a438b3",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ffa8b-63e8-49b6-b7a5-380a0db27b66",
   "metadata": {},
   "source": [
    "---\n",
    "### `genotype_matrix_windows()`\n",
    "#### Purpose:\n",
    "`genotype_matrix_windows()` is a helper function that splits a genotype matrix into non-overlapping windows and assigns positions that are variable across populations to a window according to their position. By default, the length of the simulated genome is 20 million base pairs. Each window is 500 base pairs long, with inclusive/exclusive bounds (ex. [0,500]). This results in 40,000 windows ranging from [0, 20,000,000].\n",
    "#### Input:\n",
    "- `variant_positions`: an array of the positions of variant sites across populations. Each index represents a separate variant (ordered by relative position but not evenly spaced), and its corresponding cell value represents the location of that variant position on the genome.\n",
    "- `polarized_genotype_matrix`: an array of multiple populations. It includes the ancestral population whose introgression is being inferred (Neanderthals), the population in whom introgression is being tested (Europeans), one or more sister populations to the one being tested, as a control (Africans), and an \"ancestral state\" reference population against which the rest can be polarized (Chimpanzee). Only biallelic sites are included. The ancestral allele and all identical populations are represented by '0' while the derived mutated allele is represented by '1'.\n",
    "- `window_size` The size of each window here is set to 500 by default. In Prufer's 2014 paper, the team used a genetic map, with crossover positions. We will map the genetic position by relative physical location on the chromosome \\[0 to 20,000,000).\n",
    "- `sequence_length`: the length of the simulated genome being tested. Set to 20,000,000 by default.\n",
    "\n",
    "#### Output:\n",
    "`windows` (dictionary). It has the following key ==> value relationship:\n",
    "\n",
    "*Window number (from 1 to 40,000) => [window start position, window end position, index of variant position in the input array].*\n",
    "\n",
    "Types are:\n",
    "`int => array[int, int, int...]`\n",
    "\n",
    "If there are multiple variant positions within a window, their indices in the input array of variant positions are appended to the value array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0765f206-5ce0-4fc1-a2e9-795919e0400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genotype_matrix_windows(\n",
    "        variant_positions,\n",
    "        polarized_genotype_matrix,\n",
    "        window_size=500,\n",
    "        sequence_length=20_000_000,\n",
    "):\n",
    "    # Intialize a dictionary with the start and stop position for each window.\n",
    "    windows = {}\n",
    "    index = 1\n",
    "    # Create consistent-length windows spanning the length of the sequence\n",
    "    for window_start in range(0, int(sequence_length), int(window_size)):\n",
    "        # The index (window number) is set as the key to a value of an array which contains its start and stop position\n",
    "        windows[index] = [window_start, (window_start + window_size)]\n",
    "        index += 1\n",
    "    # Locate and assign each variant position to its respective window\n",
    "    # keeps track of index number in the variant_position array\n",
    "    index = 0\n",
    "    pos = variant_positions[index]\n",
    "    for key in windows:\n",
    "        # extract the window bounds\n",
    "        start, stop = windows[key]\n",
    "        # \"bin\" the variant a the window if it is within bounds\n",
    "        while start <= pos < stop:\n",
    "            # append the index of the variant position to the corresponding value array in windows\n",
    "            windows[key].append(index)\n",
    "            index += 1\n",
    "            if index < len(variant_positions):\n",
    "                pos = variant_positions[index]\n",
    "            else: # (all variant positions have been binned)\n",
    "                break\n",
    "    # window # (1-40,000) -> [0 (start), 500 (stop), index of local variable positions (if any)]\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bd99a3-4703-4391-87bc-acd3079f7330",
   "metadata": {},
   "source": [
    "---\n",
    "### `calc_window_intro_percent()`\n",
    "#### Purpose:\n",
    "`calc_window_intro_percent()` stores the locations of genomic regions that are a result of the archaic population introgression that the HMM will infer. Known as \"true introgression positions,\" these segments represent the hidden states of the HMM. In practice, the exact loci in modern human DNA that are a result of Neanderthal introgression cannot be known, so in order to evaluate the model's efficacy and compare its performance, we record the true introgression positions during data simulation to create an \"answer key\".\n",
    "\n",
    "To this end, this function creates a dictionary of windows similar to the one created by `genotype_matrix_windows()`, but instead of recording the bounds and variant positions of each window, it represents how much each window is covered by a segment of \"true introgression\" as a percentage value. The data structure allows the quick identification of areas of true introgression in the genome, which allows the HMM's accuracy to be evaluated.\n",
    "\n",
    "#### Input:\n",
    "- `Binned_windows`: a dictionary where the keys represent the iwndow number from 1 to 40,000 and the values are arrays where the first two elements represent positional boundaries, and any following elements represent the index of variant positions that lie within that window in the `variant_positions` array. Binned_windows is the direct output of `genotype_matrix_windows`.\n",
    "- `true_introgression_positions`: nparray representing the locations of introgressed loci on the genome. Each row represents a different introgressed segment. The first column represents its starting location, and the second column represents its stopping location.\n",
    "\n",
    "#### Output:\n",
    "- `Win_intro_percent`: a dictionary of 500 base pair bins and their contents included to keep track of the true introgression state windows. The key is the window number and the value is a float percentage between 0 and 1 of how much of the window is covered by the true introgression segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52b99e7a-81c0-49ca-b97a-5d525953ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_window_intro_percent(Binned_windows, true_introgression_positions):\n",
    "\n",
    "    Windows = Binned_windows\n",
    "    true_intro_pos = true_introgression_positions\n",
    "    \n",
    "    # Initializing dictionary of Window Introgression Percentages\n",
    "    Win_intro_percent = {}\n",
    "    # Extract the columns into numpy arrays and round.\n",
    "    # Sorting makes iterating easier. Not changing any start positions. intro_starts is 'official' starting position\n",
    "    intro_starts = np.sort(np.round(true_intro_pos[:, 0]))\n",
    "    intro_stops = np.sort(np.round(true_intro_pos[:, 1]))\n",
    "    intro_sizes = np.sort(intro_stops - intro_starts)\n",
    "\n",
    "    # The index of the true introgression segment in start/stop/sizes\n",
    "    intro_index = 0\n",
    "    for key in Windows:\n",
    "        # if intro_index is the same as the number of true introgressed segments, we can end and assign the rest 0\n",
    "        if intro_index == intro_sizes.shape[0]:\n",
    "            Win_intro_percent[key] = 0.\n",
    "        else:\n",
    "            # Tracking indices\n",
    "            # integer starting and ending positions of the true introgressed segments\n",
    "            curr_start = int(intro_starts[intro_index])\n",
    "            curr_stop = int(intro_stops[intro_index])\n",
    "            # integer offset of curr_start and curr_stop from most recent window\n",
    "            curr_start_mod = int(intro_starts[intro_index] % 500)\n",
    "            curr_stop_mod = int(intro_stops[intro_index] % 500)\n",
    "            # current window that contains the beginning or end of the current segment\n",
    "            curr_start_window = int(((curr_start - curr_start_mod) / 500) + 1)\n",
    "            curr_stop_window = int(((curr_stop - curr_stop_mod) / 500) + 1)\n",
    "            # boolean that tracks whether the segment falls completely within a window (exception)\n",
    "            tiny_intro = curr_stop - curr_start < 500\n",
    "            # skips windows that come before the current start window\n",
    "            if key < curr_start_window:\n",
    "                Win_intro_percent[key] = 0.\n",
    "            elif key == curr_start_window:\n",
    "                # If the introgressed segment is less than 500, we need to do a special case to find the percentage\n",
    "                if tiny_intro:\n",
    "                    Win_intro_percent[key] = (curr_stop - curr_start) / 500\n",
    "                    # since this counts as a whole segment, we have to tick the index to seach for the next segment\n",
    "                    intro_index += 1\n",
    "                else:  # normal case, the true introgressed segment is over 500 base pairs long\n",
    "                    # calculates the % of the window that is covered by the segment from curr_start to the window's end\n",
    "                    Win_intro_percent[key] = (Windows[key][1] - curr_start) / 500\n",
    "            # In the middle of the introgressed segment, so each window is 100% covered\n",
    "            elif curr_start_window < key < curr_stop_window:\n",
    "                Win_intro_percent[key] = 1.\n",
    "            # In the last window containing the segment. It should be partially introgressed.\n",
    "            elif key == curr_stop_window:\n",
    "                # calculates the % of the window that is covered by the segment from the window's start to curr_stop\n",
    "                Win_intro_percent[key] = (curr_stop - Windows[key][0]) / 500\n",
    "                # since we found the stop window of a large segment, we can move onto the next segment, if any\n",
    "                intro_index += 1\n",
    "                # check to make sure that we record the same number of windows as there are segments\n",
    "                if intro_index > intro_sizes.shape[0]:\n",
    "                    print(\"ERROR: Recorded more windows than there are segments\")\n",
    "                    break\n",
    "            else:  # Error check\n",
    "                print(\"----------------------\")\n",
    "                print(\"ERROR: bug in key iteration for calculation of introgression percentages\")\n",
    "                print(\"----------------------\")\n",
    "                break\n",
    "\n",
    "    return Win_intro_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89443058-b35a-41f2-9ba2-7fc5380c5f49",
   "metadata": {},
   "source": [
    "### `logsum()`\n",
    "#### Purpose: \n",
    "`logsum()` takes the numpy builtin function `numpy.logaddexp()` and expands its usage to multidimensional arrays. `numpy.logaddexp()` is used to calculate the logarithm of the sum of exponentiations of the inputs. This is useful in statistical methodologies where the calculated probabilites of events become so small they exceed the range of floating point numbers and the computer loses information by rounding them to zero.\n",
    "\n",
    "In this model, some derived values can be smaller than 1*10^-130.\n",
    "\n",
    "In cases like these,  calculation values are stored as the logarithm of the true probability. `logaddexp()` allows such probabilities to be added, as in the format `log(exp(arr1) + exp(arr2))`. \n",
    "\n",
    "`logsum()` is a more flexible version which can take in multidimensional arrays as valid input by stringing all data into a one-dimensional array by appending rows one after another. `logaddexp()` only typically works on a 1-dimensional array `[1, 2, 3, 4]`, but `logsum()` accounts for the case of multiple dimensions by converting the input into the 1-D format that `logaddexp()` can recognize: for example, by convering the array `[[1, 2], [3, 4]]` into the proper dimensions before `logaddexp()` is called. `logsum()` can still take in 1-D arrays as input.\n",
    "\n",
    "#### Input:\n",
    "- `array`: a numpy array, either of one or multiple dimensions.\n",
    "\n",
    "#### Output:\n",
    "- `sum`: the sum of log probabilities within the array, in log form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "267dee17-79ba-4f6b-9a6e-cc6909548edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsum(array):\n",
    "    # If the array is of multiple dimensions, it is 'flattened' along one dimension\n",
    "    if len(array.shape) > 1:\n",
    "        vec = np.reshape(array, (np.product(array.shape),))\n",
    "    else:\n",
    "        vec = array\n",
    "    # the recurrence relation has to include a base case\n",
    "    # before the sum is initialized the base case is negative infinity,\n",
    "    # which has an underlying probability of zero from a logaddexp perspective\n",
    "    sum = np.NINF\n",
    "    for num in vec:\n",
    "        sum = logaddexp(sum, num)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b840b9c7-cf2c-4bb1-8d29-f0e7d0c3e2fa",
   "metadata": {},
   "source": [
    "### `calc_alpha()`\n",
    "\n",
    "#### Purpose:\n",
    "In the context of a HMM, the forward variable, or alpha, gives the probability of being in a certain state after observing some prefix of the emission sequence. A prefix refers to some number t characters starting from the beginning of the observed sequence. Starting by having \"seen\" none of these characters and iteratively building on these probabilities, the alpha matrix answers the question: \"What is the probability that we will be in each state after having seen t characters of the observed sequence?\" `calc_alpha()` creates this matrix so that the forward variable is calculated for all positions in the observed sequence.\n",
    "\n",
    "#### Input:\n",
    "- `A`: a 2x2 array of state transition probabilities\n",
    "- `B`: a 2x2 array of observation emission probabilities\n",
    "- `pi`: a 2x1 arry of initial state probabilities\n",
    "- `Ob`: a string representing the observed sequence (binary-encoded numbers indexed to labels: O=N, 1=C)\n",
    "- `N`: the number of states (in this case, 2: {Species, Introgressed})\n",
    "- `T`: the length of the observed sequence (set to 40,000)\n",
    "\n",
    "#### Output:\n",
    "- `alpha`: a matrix that stores the forward variable alpha, which is the probability of observing some prefix of length `t` of the emission sequence and being in some given state `j` at the end of the prefix. `alpha[t][j]` gives the probability of observing the first `t` characters of the sequencing and ending at state `j`. It has dimensions `(T+1) X N` because the first row represents the state after 0 prefix characters, which is the same as the initial distribution likelihood - found in `pi`.\n",
    "\n",
    "The following is a visual representation of the alpha matrix. The first row and first column are for labeling purposes only. Note that the values in the last row comprise the total probability of the observed sequence being produced by the HMM, and the matrix is filled from top to bottom\n",
    "\n",
    "| Prefix Length | State 0 (ends in Species) | State 1 (ends in Introgressed) |\n",
    "| --- | --- | --- |\n",
    "| t=0 | P(first state is S) | P(first state is I) |\n",
    "| t=1 | P(ends at state S \\| seen 1 observation) | P(ends at state I \\| seen 1 observation) |\n",
    "| t=2 | P(ends at state S \\| seen 2 observations) | P(ends at state I \\| seen 2 observations) |\n",
    "...\n",
    "| T=40,000 | P(ends at state S \\| seen 40k observations) | P(ends at state I \\| seen 40k observations) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98f4bb6d-1650-4070-8f92-bd769158a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alpha(A, B, pi, Ob, N, T):\n",
    "    \n",
    "    # Must be T+1 columns in the alpha matrix bc the top one is the state after 0 prefix characters\n",
    "    # This is the same as the initial distribution likelihood found in pi\n",
    "    alpha = np.zeros((T + 1, N))\n",
    "    # initialize the first row to be the initial distribution values\n",
    "    # represents the probabilities of being in some state (S/1st or I/2nd) before seeing any (t=0) observed emissions\n",
    "    alpha[0, :] = pi\n",
    "    \n",
    "    # Compute each row, starting with 2nd row. 1st row filled in last step.\n",
    "    # t counts the character number in the sequence.\n",
    "    for t in range(1, T + 1):\n",
    "        \n",
    "        # k stores the character of the previous observed emission\n",
    "        k = Ob[t - 1]\n",
    "        # Compute each column, starting with 1st (Species state) then 2nd (Introgression state)\n",
    "        for j in range(N):\n",
    "            \n",
    "            # Placeholder is set to negative infinity the first time each cell is encountered, resetting it.\n",
    "            # It stores a probability interpreted by logaddexp as zero when calculating the first logsum\n",
    "            lprob = np.NINF\n",
    "            # The i loop occurs in a single cell, the variable iterating over the states in the previously-calculated row\n",
    "            # Inside the cell, calculate the sum of probabilities (in log form) of the transitions from all possible\n",
    "            # previous states in time t-1 (the previous row) into the new state j.\n",
    "            # In this case, N=2, meaning there were 2 possible previous states that could have led to the current one\n",
    "            # This code answers: \"What is the probability that each possible scenario (previous state being S or I) led to\n",
    "            # our current state j?\" When the loop is finished, the value of the cell is set to the combination of those probabilities.\n",
    "            for i in range(N):\n",
    "                \n",
    "                # lp represents a sum of log probabilities:\n",
    "                # (forward variable at time t-1 for state i)\n",
    "                # + likelihood that last row's state i transitioned to this state j using the transition matrix A\n",
    "                # + the likelihood that state i emitted this observed character k using the emission matrix B\n",
    "                lp = alpha[t - 1][i] + A[i][j] + B[i][k]\n",
    "                # during the first iteration, lprob is reset as equal to lp, as lprob starts set to NINF\n",
    "                # the second time around, lp is recalculated and represents the probability that the current state j\n",
    "                # was reached from the Introgressed state. Now, calling logaddexp(lprob, lp) represents the sum of these:\n",
    "                # (prob we're in state j if the last state was S + prob we're in state j if the last state was I)\n",
    "                lprob = logaddexp(lprob, lp)\n",
    "                \n",
    "            # After the probabilities based on both of the cells in the previous row were treated and combined,\n",
    "            # the final number is set as the forward variable:\n",
    "            # the likelihood we observe prefix (...t) of the observe sequence and end up in state j\n",
    "            alpha[t][j] = lprob\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896243e8-c11a-46b1-903d-c525dcb627f0",
   "metadata": {},
   "source": [
    "### `calc_beta()`\n",
    "\n",
    "#### Purpose:\n",
    "In the context of a HMM, the backward variable, or beta, gives the probability of being in a certain state `j` just before observing a suffix of the emission sequence of length `t`. A suffix refers to some number `t` of the last characters in the sequence. Starting by having \"seen\" none of these chraracters and building on its own probabilities in reverse order, the beta matrix answers the question: \"What is the probability of being in state `j` right before the last `T-t` characters of the observed sequence (where `T` is the length of the sequence)?\" `calc_beta()` creates this matrix so that the backward variable is calculated for all positions in the observed sequence.\n",
    "\n",
    "\n",
    "#### Input:\n",
    "- `A`: a 2x2 array of state transition probabilities\n",
    "- `B`: a 2x2 array of observation emission probabilities\n",
    "- `pi`: a 2x1 arry of initial state probabilities\n",
    "- `Ob`: a string representing the observed sequence (binary-encoded numbers indexed to labels: O=N, 1=C)\n",
    "- `N`: the number of states (in this case, 2: {Species, Introgressed})\n",
    "- `T`: the length of the observed sequence (set to 40,000)\n",
    "\n",
    "#### Output:\n",
    "- `beta`: a matrix that stores the backward variable beta, which is the probability of being in some given state `j` before observing some suffix of length `t` of the emission sequence. `beta[t][j]` gives the probability of being in state `j` before seeing a suffix of length `t`. There must be `T+1` columns in the beta matrix because the final row (which is filled first in the calculation) represents the state chances before 0 suffix characters have been observed. The initial state is assumed as given (prior probability = 100%), so its value is 1. \n",
    "\n",
    "The following is a visual representation of the beta matrix. The first row and first column are for labeling purposes only. Note that the values in the top row comprise the total probability of each state preceding the entire observed sequence, and the matrix is filled from bottom to top.\n",
    "\n",
    "| Suffix Length | State 0 (came from Species) | State 1 (came from Introgressed) |\n",
    "| --- | --- | --- |\n",
    "| t=0 | P(will see all 40k observations \\| after S) | P(will see all 40k observations \\| after I) |\n",
    "...\n",
    "| t=39,998 | P(will see last 2 observations \\| after S) | P(will see last 2 observations \\| after I) |\n",
    "| t=39,999 | P(will see last 1 observation \\| after S) | P(will see last 2 observation \\| after I) |\n",
    "| t=40,000 | P(will see last 0 observations \\| after S) | P(will see last 0 observations \\| after I) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e5fd2ef-d8f6-4a74-8a53-562459bf3a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_beta(A, B, Ob, N, T):\n",
    "    # Must be T+1 columns in the beta matrix because the bottom one is the state before a 0-character suffix\n",
    "    # This is given as 100% in the base case, so we still initialize the matrix to zeroes.\n",
    "    # This is because the underlying proability assumed by the logaddexp occurrence is 1 (log(1) = 0).\n",
    "    beta = np.zeros((T + 1, N))\n",
    "    \n",
    "    # Compute each row, starting with the 2nd from the bottom. The bottom row was filled out during initialization.\n",
    "    # t counts the position of the state relative to the sequence\n",
    "    for t in range(T - 1, -1, -1):\n",
    "        \n",
    "        # k stores the character just after (emitted by) the state being investigated\n",
    "        k = Ob[t]\n",
    "        # Compute each column, starting with 1st (Species state) then 2nd (Introgression state)\n",
    "        for j in range(N):\n",
    "            \n",
    "            # Placeholder is set to negative infinity the first time each cell is encountered, resetting it.\n",
    "            # It stores a probability interpreted by logaddexp as zero when calculating the first logsum\n",
    "            lprob = np.NINF\n",
    "            # The i loop occurs in a single cell, the variable iterating over the states in the previously-calculated row\n",
    "            # Inside the cell, calculate the sum of probabilities (in log form) of the transitions from all possible\n",
    "            # previous states in time t+1 (the previous/lower row) to the current row t.\n",
    "            # This code answers: \"What is the probability that each state was arrived at through the emission of\n",
    "            # the most recent suffix character k from our current state in column j and a subsequent transition\n",
    "            # from state j to i?\" When the loop is finished, the value of the cell is set to the combination of those probabilities.\n",
    "            for i in range(N):\n",
    "                \n",
    "                # lp represents a sum of log probabilities:\n",
    "                # (backward variable at time t+1 for state i)\n",
    "                # + likelihood that the lower row's state i transitioned to this state j using the transition matrix A\n",
    "                # + the likelihood that state i emitted this observed character k using the emission matrix B\n",
    "                lp = beta[t + 1][i] + A[j][i] + B[j][k]\n",
    "                # during the first iteration, lprob is reset as equal to lp, as lprob starts set to NINF\n",
    "                # the second time around, lp is recalculated and represents the probability that the current state j\n",
    "                # transitioned the Introgressed state. Now, calling logaddexp(lprob, lp) represents the sum of these:\n",
    "                # (prob we're in state j if the next state is S + prob we're in state j if the next state is I)\n",
    "                lprob = logaddexp(lprob, lp)\n",
    "                \n",
    "            # After the proababilities based on both of the cells in the lower row were treated and combined,\n",
    "            # the final number is set as the backward variable:\n",
    "            # the likelihood we observe suffix(t...) of the observed sequence as a result of state j\n",
    "            beta[t][j] = lprob\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b831c33-827a-4d82-8740-8c0c30e370a9",
   "metadata": {},
   "source": [
    "#### `calc_xi()`\n",
    "\n",
    "#### Purpose:\n",
    "In the context of a HMM, the xi variable gives the probability of being in a certain state state `i` at time `t` and state `j` at time `t + 1`. One can imagine the xi matrix as leveraging the forward and backward variables to calculate the probabilities of a transition between all possible pairs of hidden states between every two positions in the observed sequence. The xi matrix answers the question: \"What is the probability that the state transition `i` to `j` occurred from position `t` to position `t + 1`?\"\n",
    "\n",
    "#### Input:\n",
    "- `A`: a 2x2 array of state transition probabilities\n",
    "- `B`: a 2x2 array of observation emission probabilities\n",
    "- `Ob`: a string representing the observed sequence (binary-encoded numbers indexed to labels: O=N, 1=C)\n",
    "- `N`: the number of states (in this case, 2: {Species, Introgressed})\n",
    "- `T`: the length of the observed sequence (set to 40,000)\n",
    "- `alpha`: the matrix containing the forward variable, calculated by `calc_alpha`\n",
    "- `beta`: the matrix containing the backward variable, calculated by `calc_beta`\n",
    "\n",
    "#### Output:\n",
    "- `xi`: a matrix where `xi[i][j][t]` gives the probability of being in state `i` at time `t` and transitioning to state `j` at time `t + 1`. and transitioning to state `j` at time `t`.\n",
    "\n",
    "The following is a visual representation of `xi`. The first row and first column are for labeling purposes only. `xi` is a three-dimensional matrix (2 X 2 X 40,000), so I've simplified it into a visual representation here. Each row corresponds to a different time or transition position between two adjacent observed characters, filled out from top to bottom (as with `alpha`). One can imagine the second table as the \"back side\" of `xi`, existing directly behind the front side in a stack, like a second sheet of paper. This model reflects how the matrix is instantiated. One can think of the whole data structure as a `NxN` (2x2) tall \"tower\" which is `T` (40,000) stories high. The inner loops will begin at coordinates `(0, 0)` on the \"top floor\" (T-level) and visit every \"room\" on that floor in a counterclockwise fashion, going down a floor when all four rooms have been evaluated. The \"top floor\" here is t=0, which represents the first state transition associated with the observed sequence. `Ob[t]` and `Ob[t+1]` here refer to the adjacent observations in the sequence at the transition position being analyzed.\n",
    "\n",
    "`xi` (Front Side):\n",
    "\n",
    "| Transition | State S -> State S | State S -> State I |\n",
    "| --- | --- | --- |\n",
    "| t=0 | P(S -> S \\| `Ob[0]` -> `Ob[1]`) | P(S -> I \\| `Ob[0]` -> `Ob[1]`) |\n",
    "...\n",
    "| t=39,997 | P(S -> S \\| `Ob[39,997]` -> `Ob[39,998]`) | P(S -> I \\| `Ob[39,997]` -> `Ob[39,998]`) |\n",
    "| t=39,998 | P(S -> S \\| `Ob[39,998]` -> `Ob[39,999]`) | P(S -> I \\| `Ob[39,998]` -> `Ob[39,999]`) |\n",
    "| t=39,999 | P(S -> S \\| `Ob[39,999]` -> end) | P(S -> I \\| `Ob[39,999]` -> end) |\n",
    "\n",
    "`xi` (Back Side):\n",
    "\n",
    "| Transition | State I -> State S | State I -> State I |\n",
    "| --- | --- | --- |\n",
    "| t=0 | P(I -> S \\| `Ob[0]` -> `Ob[1]`) | P(I -> I \\| `Ob[0]` -> `Ob[1]`) |\n",
    "...\n",
    "| t=39,997 | P(I -> S \\| `Ob[39,997]` -> `Ob[39,998]`) | P(I -> I \\| `Ob[39,997]` -> `Ob[39,998]`) |\n",
    "| t=39,998 | P(I -> S \\| `Ob[39,998]` -> `Ob[39,999]`) | P(I -> I \\| `Ob[39,998]` -> `Ob[39,999]`) |\n",
    "| t=39,999 | P(I -> S \\| `Ob[39,999]` -> end) | P(I -> I \\| `Ob[39,999]` -> end) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d0d777d-5c40-4d4b-9a3f-dbd09b44ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_xi(A, B, Ob, N, T, alpha, beta):\n",
    "    # Must be T columns in the xi matrix because there are T-1 transitions between observed characters,\n",
    "    # plus one state change from the state that emitted the last character to final state.\n",
    "    xi = np.zeros((T, N, N))\n",
    "    \n",
    "    # Compute each 2x2 row or \"floor\" of the matrix from top to bottom. t=0 represents the first transition between observations\n",
    "    for t in range(T):\n",
    "        k = Ob[t]\n",
    "        lp_traverse = np.zeros((N, N))\n",
    "        \n",
    "        # These loops will circle each \"floor\" and calculate each cell at the [i, j]th coordiante of that floor based\n",
    "        # on the corresponding alpha and beta matrix positions and the transition and emission matrices\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                \n",
    "                # lp, or the probability of this transition, is equal to the sum of\n",
    "                # P(getting to this state)\n",
    "                # P(making this transition)\n",
    "                # P(emitting this character)\n",
    "                # P(going to the end)\n",
    "                lp = (\n",
    "                        alpha[t][i]\n",
    "                        + A[i][j]\n",
    "                        + B[i][k]\n",
    "                        + beta[t + 1][j]\n",
    "                )\n",
    "                lp_traverse[i][j] = lp\n",
    "\n",
    "        # Each \"room\" on floor t has been calculated. Now that we have the values of all four cells, we can calculate\n",
    "        # the total probability of all cases on the top floor as the sum of logarithm probabilities within it.\n",
    "        # When the \"floor\" loop is over, this next step \"subtracts the logs\" (divides the probabilities) of each cell\n",
    "        # by the total probability of floor T.\n",
    "        # Normalize the probability for this time step (divide by P(O|lambda))\n",
    "        xi[t, :, :] = lp_traverse - supp.logsum(lp_traverse)\n",
    "    return xi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96fd97d-ba81-4e36-b849-6c57180e70f6",
   "metadata": {},
   "source": [
    "#### `calc_gamma`\n",
    "\n",
    "#### Purpose:\n",
    "In the context of a HMM, the gamma variable gives the probability of being in a certain state state `i` at time `t`. This is the final variable in the workflow, as it gives the probability of Human/Neanderthal ancestry for any locus. The gamma variable answers the question: \"What is the probability that the observed locus at time `t` was a result of hidden state ancestry `i`?\"\n",
    "\n",
    "#### Input:\n",
    "- `xi`: the matrix containing the xi variable, calculated by `calc_xi`\n",
    "- `N`: the number of states (in this case, 2: {Species, Introgressed})\n",
    "- `T`: the length of the observed sequence (set to 40,000)\n",
    "\n",
    "#### Output:\n",
    "- `gamma`: a matrix where `gamma[t][i]` gives the probability of being in state `i` at time `t`.\n",
    "\n",
    "\n",
    "\n",
    "The following is a visual representation of `gamma`. The first row and first column are for labeling purposes only. Since hidden state 1 (Introgressed) refers to a likely Neanderthal ancestry, we take the right column `gamma[t][1]` of this matrix as the HMM's guess that the hidden state at this location in the sequence is a result of Neanderthal introgression. `Ob[t]` refers to the observation in the sequence at the locus being analyzed.\n",
    "\n",
    "\n",
    "| Observation (500-bp locus) | State 0 (Species) | State 1 (Introgressed) |\n",
    "| --- | --- | --- |\n",
    "| t=0 | P(`Ob[0]` \\| S) | **P(`Ob[0]` \\| I)** |\n",
    "| t=1 | P(`Ob[1]` \\| S) | **P(`Ob[1]` \\| I)** |\n",
    "| t=2 | P(`Ob[2]` \\| S) | **P(`Ob[2]` \\| I)** |\n",
    "...\n",
    "| t=40,000 | P(`Ob[39,999]` \\| S) | **P(`Ob[39,999]` \\| I)** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "313c166a-0445-48ff-8f45-bbd0e44879e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gamma(xi, N, T):\n",
    "    # Must be T columns in the gamma matrix because there are T observed loci\n",
    "    gamma = np.zeros((T, N))\n",
    "    \n",
    "    # Compute each row, starting with the first and going down. Each corresponds to a locus\n",
    "    for t in range(T):\n",
    "        \n",
    "        # Compute each column, starting with the Species state (i=0) and then the Introgressed state (i=1)\n",
    "        for i in range(N):\n",
    "            \n",
    "            # Sum up the probabilities for state i at this position t by combining all relevant instances\n",
    "            # where the hidden state could be i at time t\n",
    "            gamma[t][i] = supp.logsum(xi[t, i, :])\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa7a89-1baa-4f45-a80b-95c06080e39d",
   "metadata": {},
   "source": [
    "### `update_A()`\n",
    "\n",
    "#### Purpose:\n",
    "This function is used in the Baum-Welch algorithm in order to update the transition matrix based on the real distribution of probabilities that come from the `gamma` calculated by the last iteration of the model. The transition matrix `A[i][j]` is updated by finding the sum of all transitions from positions `i` to `j` (found with `xi`), and the update normalizes this matrix by the sum of the transitions out of state `i` (found with `gamma`). It is important to remember that the HMM does not \"know\" the true states and their transitions, it is updating its own parameters by observing the frequency of its *guesses* at the true states and adjusting according to probability.\n",
    "\n",
    "#### Input:\n",
    "- `N`: the number of states (in this case, 2: {Species, Introgressed})\n",
    "- `xi`: the matrix containing the xi variable, calculated by `calc_xi`\n",
    "- `gamma`: the matrix containing the gamma variable, calculated by `calc_gamma`\n",
    "\n",
    "#### Output:\n",
    "- `A`: an updated 2x2 transition probability matrix based on the prevalence of transitions between inferred states after analyzing the observed sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7ca5737-bc4e-4979-a690-049b8c3ce26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_A(N, xi, gamma):\n",
    "    # Initialize a blank new transition matrix\n",
    "    A = np.zeros((N, N))\n",
    "    # Initialize the sum of all transitions out of i\n",
    "    trans_out = np.zeros(N)\n",
    "    \n",
    "    # for every state i in gamma (Species or Neanderthal)\n",
    "    for i in range(N):\n",
    "        # how many transitions out of state i were there\n",
    "        # summing probabilities because a confidence of 1 counts as 1 transition, 50% confidence counts as half, etc.\n",
    "        trans_out[i] = supp.logsum(gamma[:, i])\n",
    "    \n",
    "    # for every starting state i in xi\n",
    "    for i in range(N):\n",
    "        # for every receiving state j in xi\n",
    "        for j in range(N):\n",
    "            # A (transition) [i][j] is the sum of all the transitions from i to j\n",
    "            # This normalized by the previously-calculated sum of the total number of inferred transitions from state i\n",
    "            A[i][j] = supp.logsum(xi[:, i, j]) - trans_out[i]\n",
    "            \n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243da161-924a-46c5-aaa0-7a262eee4fc6",
   "metadata": {},
   "source": [
    "### `update_B()`\n",
    "\n",
    "#### Purpose:\n",
    "This function is used in the Baum-Welch algorithm in order to update the emission matrix based on the real distribution of emissions from inferred true states that come from the `xi` calculated by the last iteration of the model. The transition matrix `A[i][j]` is updated by finding the sum of all transitions out of `i` when emission `k` is observed and dividing by the total number of transitions out of `i`.\n",
    "\n",
    "#### Input:\n",
    "- `Ob`: a string representing the observed sequence (binary-encoded numbers indexed to labels: O=N, 1=C)\n",
    "- `N`: the number of states (in this case, 2: {Species, Introgressed})\n",
    "- `M`: the number of possible observations (in this case, 2: {N (Not Consistent), C (Consistent)})\n",
    "- `T`: the length of the observed sequence (set to 40,000)\n",
    "- `xi`: the matrix containing the xi variable, calculated by `calc_xi`\n",
    "\n",
    "#### Output:\n",
    "- `B`: an updated 2x2 emission probability matrix based on the prevalence of emissions from inferred states after analyzing the observed sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "190000c5-9fdd-4ae3-9110-ebdb12cc31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_B(Ob, N, M, T, xi):\n",
    "    # Initialize a blank new emission matrix\n",
    "    B = np.zeros((N, M))\n",
    "    # For every state i\n",
    "    for i in range(N):\n",
    "        # Initialize the matrix of all emissions from state i\n",
    "        # ksum[k] is the sum of all i with k\n",
    "        ksum = np.zeros(M) + log_zero\n",
    "        # for every observed locus t in the sequence\n",
    "        for t in range(T):\n",
    "            # set k to the observation at the current locus\n",
    "            k = Ob[t]\n",
    "            # for every state j\n",
    "            for j in range(N):\n",
    "                # find the sum of all emissions of k from state i when transitioning to each state j and add them\n",
    "                ksum[k] = logaddexp(ksum[k], xi[t, i, j])\n",
    "        # Normalize the sum of all emissions of k from that state i by the sum of all emissions at that position\n",
    "        ksum = ksum - supp.logsum(ksum)\n",
    "        # Set the new emission matrix to the normalized probability of every type of emission k from state i\n",
    "        B[i, :] = ksum\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27882a2-966c-43fc-95a7-de5f20e073b2",
   "metadata": {},
   "source": [
    "### `update_pi`\n",
    "\n",
    "#### Purpose:\n",
    "This function is used in the Baum-Welch algorithm in order to update the initial distribution matrix based on the inferred first true state that comes from the `gamma` calculated by the last iteration of the model. The initial distribution matrix `pi[i]` is updated by finding the probability of the first state being state `i` as calculated under the previous model's parameters.\n",
    "\n",
    "#### Input:\n",
    "- `N`: the number of states (in this case, 2: {Species, Introgressed})\n",
    "- `gamma`: the matrix containing the gamma variable, calculated by `calc_gamma`\n",
    "\n",
    "#### Output:\n",
    "- `pi`: an updated 1x2 initial distribution probability matrix based on the probability of true states at the first observed locus in the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66ce2349-421f-4202-8f7a-5d6133785e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteratively update pi\n",
    "def update_pi(N, gamma):\n",
    "    # Initialize a blank new initial distribution matrix\n",
    "    pi = np.zeros(N)\n",
    "    # for every state i\n",
    "    for i in range(N):\n",
    "        # The adjusted chances that a observed sequence will start on state i\n",
    "        # are set to the probability that the first locus was i in the last iteration of the model\n",
    "        pi[i] = gamma[0][i]\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08489d37-e0aa-479f-a818-a1b2002de383",
   "metadata": {},
   "source": [
    "### `eval_accuracy`\n",
    "\n",
    "#### Purpose:\n",
    "This function measures the performance of an HMM against true introgression positions.\n",
    "\n",
    "#### Input:\n",
    "- `true_windows`: numpy array of windows containing introgressed sites measured by percentage coverage. Some sites will have incomplete window edges.\n",
    "## NOTE: HOW TO DEAL WITH THIS IN PERFORMANCE EVALUATION\n",
    "- `tested_HMM`: numpy gamma matrix returned from HMM. Represents likelihood of introgression at position. Should be pre-exponentiated (float probabilities not logs).\n",
    "- `normalized`: Boolean determining behavior of algorithm (default True). False will evaluate HMM correct \"guesses\" as they are presented: are they over the threshold or not? True will adjust the HMM \"guesses\", treating them as relative likelihoods: the highest scoring window is set to 1 and other probabilities are normalized accordingly, then evaluated in relation to the original threshold\n",
    "- `threshold`: float representing the level of certainty about a true state being introgressed that `gamma` must have in order for the inference to be counted as a guess\n",
    "\n",
    "#### Output:\n",
    "- `performance`: numpy array of floats `[false_pos_r, miss_rate, sensitivity, specificity]`\n",
    "- `false_pos_r`: float of \"false positive\" rate or (# false positivies / (# false positives + # true negatives)). The probability that a true negative ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb7b4b6c-3cfc-45ea-9bb7-14ca80488669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c80fa751-4d8d-4387-82bb-88e982417e45",
   "metadata": {},
   "source": [
    "### Not Included Because They Contain Other Functions: `extract_O()` and `hmm()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d956d0d3-da16-404e-aa8e-5032aee2635a",
   "metadata": {},
   "source": [
    "---\n",
    "## Example Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0becc5-9c04-44b2-b324-62c05603ee94",
   "metadata": {},
   "source": [
    "1) Explain types of simulated data\n",
    "2) Load in simulated data\n",
    "3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97133957-31d5-475d-a725-e74790e35360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96837c5b-faf4-41a5-9a4d-4be56ff5468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d906ee-a73a-4897-8824-588bd61fcdbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da463de3-3538-483b-8770-e05addeeb257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ec29a3-1ebb-485f-98ad-ef88da99842c",
   "metadata": {},
   "source": [
    "---\n",
    "### Workflow function\n",
    "\n",
    "#### Done step by step\n",
    "\n",
    "#### Once as a large function, compare its output to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06db90e8-701d-44cb-a218-8d676a75b77f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
